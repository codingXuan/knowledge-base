import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,b as e,o as r}from"./app-7M4PPNja.js";const i={};function l(o,s){return r(),a("div",null,s[0]||(s[0]=[e(`<h4 id="_1-核心定位与关系-强大的引擎与优雅的接口" tabindex="-1"><a class="header-anchor" href="#_1-核心定位与关系-强大的引擎与优雅的接口"><span><strong>1. 核心定位与关系：强大的引擎与优雅的接口</strong></span></a></h4><p>TensorFlow 是由 Google 开发的、一个用于高性能数值计算的开源平台。它的设计初衷就是为了应对大规模的、分布式的训练和部署场景，在工业界有着极其深厚的基础。</p><p>Keras 则是一个高级神经网络API，它以**“以人为本”**为设计原则，旨在实现快速、简单的原型设计。它的接口清晰、模块化，极大地降低了深度学习的入门门槛。</p><p><strong>现代关系</strong>：从TensorFlow 2.x开始，Keras 已被完全整合并作为其官方唯一推荐的高级API，我们通过 <code>tensorflow.keras</code>（通常简写为<code>tf.keras</code>）来使用它。可以这样理解：<strong>我们使用Keras简洁的语法来定义模型，而底层的计算、优化和部署则由强大的TensorFlow引擎来执行。</strong></p><h4 id="_2-tensorflow-底层的计算引擎" tabindex="-1"><a class="header-anchor" href="#_2-tensorflow-底层的计算引擎"><span><strong>2. TensorFlow：底层的计算引擎</strong></span></a></h4><p>尽管我们现在大多通过Keras来使用它，但了解TensorFlow的底层特点依然重要：</p><ul><li><strong>静态计算图 (Static Graph / Define-and-Run)</strong>：这是早期TensorFlow与PyTorch最大的区别。在TensorFlow 1.x中，需要先定义整个神经网络的计算图，然后再向这个图中“填充”数据并执行它。这种“先定义再运行”的模式，非常有利于进行编译优化和跨平台部署（如部署到服务器、移动端、TPU等）。 <ul><li><strong>演进</strong>：从TensorFlow 2.x开始，默认启用了<strong>Eager Execution（即时执行）</strong>，使其行为变得和PyTorch的动态图非常相似，更加直观和易于调试。</li></ul></li><li><strong>强大的生态系统与部署能力</strong>： <ul><li><strong>TensorBoard</strong>：一个无与伦比的可视化工具，可以监控训练过程中的loss、准确率、网络结构、参数分布等各种指标。</li><li><strong>TensorFlow Serving</strong>：专为生产环境设计的、用于部署模型的高性能服务系统。</li><li><strong>TensorFlow Lite (TFLite)</strong>：用于将模型部署到移动和嵌入式设备的轻量级解决方案。</li></ul></li></ul><h4 id="_3-keras-上层的用户友好api" tabindex="-1"><a class="header-anchor" href="#_3-keras-上层的用户友好api"><span><strong>3. Keras：上层的用户友好API</strong></span></a></h4><p>Keras的哲学是“让简单的事情更简单，让复杂的事情成为可能”。</p><ul><li><strong>核心组件</strong>: <ul><li><code>**layers**</code>：Keras提供了丰富的、标准化的层，如 <code>Dense</code> (全连接层), <code>Conv2D</code>, <code>LSTM</code> 等，可以通过堆叠这些层来快速构建模型。</li><li><code>**Model**</code>: 构建模型的两种主要方式： <ol><li><code>**Sequential**</code>** API**：用于构建简单的、层从头到尾线性堆叠的模型，代码极其简洁。</li><li><strong>Functional API</strong>：用于构建更复杂的、具有多输入、多输出或分支结构的模型图。</li></ol></li></ul></li><li><strong>标准化的工作流</strong>：Keras将一个典型的训练流程抽象成了三个核心方法： <ol><li><code>**model.compile()**</code>: <strong>配置训练过程</strong>。在这一步，您需要指定优化器（optimizer）、损失函数（loss function）和评估指标（metrics）。</li><li><code>**model.fit()**</code>: <strong>执行训练</strong>。您只需将训练数据和验证数据“喂”给这个方法，并指定训练的轮次（epochs）和批次大小（batch_size），Keras会自动处理整个训练循环（包括前向传播、计算损失、反向传播和参数更新）。</li><li><code>**model.evaluate()**</code>** / **<code>**model.predict()**</code>: <strong>评估与预测</strong>。训练完成后，用这两个方法来评估模型性能或进行新的预测。</li></ol></li></ul><h4 id="_4-代码示例-一个完整的-tf-keras-训练流程" tabindex="-1"><a class="header-anchor" href="#_4-代码示例-一个完整的-tf-keras-训练流程"><span><strong>4. 代码示例：一个完整的 <strong><code>**tf.keras**</code></strong> 训练流程</strong></span></a></h4><p>我们用和PyTorch示例完全相同的任务（拟合<code>y = 2x + 1</code>），来看看用<code>tf.keras</code>实现有多么简洁。</p><p>Python</p><div class="language-plain line-numbers-mode" data-highlighter="shiki" data-ext="plain" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-plain"><span class="line"><span>import tensorflow as tf</span></span>
<span class="line"><span>import numpy as np</span></span>
<span class="line"><span></span></span>
<span class="line"><span># --- 1. 数据准备 ---</span></span>
<span class="line"><span># Keras通常与NumPy数组配合得很好</span></span>
<span class="line"><span>X_numpy = np.arange(0, 10, 0.1).reshape(-1, 1).astype(np.float32)</span></span>
<span class="line"><span>y_numpy = 2 * X_numpy + 1 + np.random.randn(X_numpy.shape[0], 1).astype(np.float32) * 0.5</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span># --- 2. 模型构建 (使用Keras Sequential API) ---</span></span>
<span class="line"><span># 像搭积木一样，一层一层地堆叠</span></span>
<span class="line"><span>model = tf.keras.Sequential([</span></span>
<span class="line"><span>    # 添加一个全连接层(Dense)，输入维度是1，输出维度也是1</span></span>
<span class="line"><span>    tf.keras.layers.Dense(units=1, input_shape=[1])</span></span>
<span class="line"><span>])</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span># --- 3. 配置训练过程 (compile) ---</span></span>
<span class="line"><span># 指定优化器（使用SGD）和损失函数（使用均方误差）</span></span>
<span class="line"><span>model.compile(optimizer=&#39;sgd&#39;, loss=&#39;mean_squared_error&#39;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span># --- 4. 执行训练 (fit) ---</span></span>
<span class="line"><span># 将数据“喂”给fit方法，Keras会自动处理所有循环和更新</span></span>
<span class="line"><span># verbose=0表示在训练时不打印日志</span></span>
<span class="line"><span>history = model.fit(X_numpy, y_numpy, epochs=100, verbose=0)</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span># --- 5. 使用训练好的模型进行预测 ---</span></span>
<span class="line"><span>print(&quot;训练完成!&quot;)</span></span>
<span class="line"><span># Keras将权重和偏置封装在层的内部</span></span>
<span class="line"><span>layer = model.layers[0]</span></span>
<span class="line"><span>trained_weight = layer.get_weights()[0][0][0]</span></span>
<span class="line"><span>trained_bias = layer.get_weights()[1][0]</span></span>
<span class="line"><span>print(f&quot;模型学到的规律: y = {trained_weight:.4f}x + {trained_bias:.4f}&quot;)</span></span>
<span class="line"><span>print(&quot;真实规律是: y = 2.0000x + 1.0000&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 用一个新数据点进行预测</span></span>
<span class="line"><span>new_x = np.array([[15.0]])</span></span>
<span class="line"><span>predicted_y = model.predict(new_x)</span></span>
<span class="line"><span>print(f&quot;\\n当 x = 15.0 时, 模型的预测值 y = {predicted_y[0][0]:.4f}&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_5-pytorch-vs-tensorflow-keras-哲学对比" tabindex="-1"><a class="header-anchor" href="#_5-pytorch-vs-tensorflow-keras-哲学对比"><span><strong>5. PyTorch vs. TensorFlow/Keras 哲学对比</strong></span></a></h4><table><thead><tr><th>特性</th><th><strong>PyTorch</strong></th><th><strong>TensorFlow / Keras</strong></th></tr></thead><tbody><tr><td><strong>核心定位</strong></td><td>灵活、强大的研究平台</td><td>可靠、可扩展的生产平台</td></tr><tr><td><strong>API风格</strong></td><td>命令式 (Define-by-Run)</td><td>声明式 (Define-and-Run) + 命令式</td></tr><tr><td><strong>控制力</strong></td><td><strong>极高</strong>，对底层操作有完全控制</td><td><strong>高</strong>，但通过Keras抽象了许多细节</td></tr><tr><td><strong>上手难度</strong></td><td>相对较陡，需要理解更多底层概念</td><td><strong>非常平缓</strong>，Keras接口极其友好</td></tr><tr><td><strong>代码简洁度</strong></td><td>相对冗长，需要手动编写训练循环</td><td><strong>极其简洁</strong>，<code>compile</code><br>和<code>fit</code><br>搞定一切</td></tr><tr><td><strong>生态强项</strong></td><td>学术界、前沿研究、NLP领域</td><td>工业界、生产部署、移动端、可视化</td></tr></tbody></table><p><strong>总结</strong>：TensorFlow/Keras提供了一个高度优化、易于上手且极其适合生产部署的端到端平台。对于希望快速将想法转化为模型，并最终部署成稳定服务的开发者来说，<code>tf.keras</code>提供了一条平坦而宽阔的道路。</p><p><strong>tips</strong>😗* <strong>之前讨论的PyTorch和TensorFlow的细节，更多的是关于如何“从零到一”地训练一个大模型。但对于99%的应用开发者来说，这个阶段已经由Google、Meta、阿里巴巴、智谱AI等大公司完成了</strong>。<strong>我们只需要站在巨人的肩膀上用已经训练好的模型进行指令微调即可。而且在现实中当今几乎所有的主流开源大语言模型（Llama、Qwen、Mistral、GLM等）和围绕它们建立的整个生态系统（如Hugging Face Transformers、PEFT、vLLM、Llama-factory等），都已经</strong>事实性地标准化在了PyTorch之上！**所以当你选择三方开源模型的时候，其实已经是选择了pytorch,不需要再去考虑是否用tk。</p>`,18)]))}const d=n(i,[["render",l]]),c=JSON.parse('{"path":"/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/TensorFlow_Keras.html","title":"TensorFlow_Keras","lang":"zh-CN","frontmatter":{"title":"TensorFlow_Keras"},"git":{"createdTime":1753758135000,"updatedTime":1753758135000,"contributors":[{"name":"codingXuan","username":"codingXuan","email":"34129858+codingXuan@users.noreply.github.com","commits":1,"url":"https://github.com/codingXuan"}]},"readingTime":{"minutes":5.32,"words":1595},"filePathRelative":"AIGC框架详解/基础框架/深度学习框架/TensorFlow_Keras.md","excerpt":"<h4><strong>1. 核心定位与关系：强大的引擎与优雅的接口</strong></h4>\\n<p>TensorFlow 是由 Google 开发的、一个用于高性能数值计算的开源平台。它的设计初衷就是为了应对大规模的、分布式的训练和部署场景，在工业界有着极其深厚的基础。</p>\\n<p>Keras 则是一个高级神经网络API，它以**“以人为本”**为设计原则，旨在实现快速、简单的原型设计。它的接口清晰、模块化，极大地降低了深度学习的入门门槛。</p>\\n<p><strong>现代关系</strong>：从TensorFlow 2.x开始，Keras 已被完全整合并作为其官方唯一推荐的高级API，我们通过 <code>tensorflow.keras</code>（通常简写为<code>tf.keras</code>）来使用它。可以这样理解：<strong>我们使用Keras简洁的语法来定义模型，而底层的计算、优化和部署则由强大的TensorFlow引擎来执行。</strong></p>"}');export{d as comp,c as data};

import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as s,a as t,o as r}from"./app-BmWXErMj.js";const i={};function o(a,e){return r(),s("div",null,e[0]||(e[0]=[t('<h4 id="_1-核心定位-大规模ai模型的-超级增压器" tabindex="-1"><a class="header-anchor" href="#_1-核心定位-大规模ai模型的-超级增压器"><span><strong>1. 核心定位：大规模AI模型的“超级增压器”</strong></span></a></h4><p>如果说PyTorch是制造发动机的工具箱，那么DeepSpeed就是一套为这款发动机设计的、集成了<strong>涡轮增压、氮气加速、先进冷却系统于一体的“极限性能改装套件”</strong>。</p><p>它的核心价值在于，让您能够在现有的硬件上，训练和推理更大规模的模型，或者以更高的效率来训练和推理同等规模的模型。它通过在并行计算、内存优化和推理加速等多个维度提供极致的优化来实现这一目标。</p><h4 id="_2-训练优化-zero——deepspeed的-黑科技" tabindex="-1"><a class="header-anchor" href="#_2-训练优化-zero——deepspeed的-黑科技"><span><strong>2. 训练优化：ZeRO——DeepSpeed的“黑科技”</strong></span></a></h4><p>ZeRO（Zero Redundancy Optimizer，零冗余优化器）是DeepSpeed名声大噪的独门秘籍，它主要用于解决训练过程中显存（VRAM）不足的问题。</p><ul><li><strong>问题的根源</strong>：在标准的**数据并行（Data Parallelism）**训练中，每个GPU都会加载一份完整的模型权重、一份完整的梯度、以及一份完整的优化器状态。对于一个大型模型来说，这三者的副本会占据海量的显存，成为最大的瓶颈。</li><li><strong>ZeRO的解决方案（分阶段进行）</strong>： <ul><li><strong>Stage 1</strong>: <strong>分割优化器状态 (Partitioning Optimizer States)</strong>。不再让每个GPU都保留完整的优化器状态，而是将其切分，每个GPU只保留一部分。这能显著减少显存占用。</li><li><strong>Stage 2</strong>: <strong>分割梯度 (Partitioning Gradients)</strong>。在Stage 1的基础上，进一步将梯度的存储也进行切分。</li><li><strong>Stage 3</strong>: <strong>分割模型权重 (Partitioning Model Weights)</strong>。这是最彻底的阶段，连模型权重本身也进行切分，每个GPU只拥有模型的一部分。在需要进行前向或反向传播时，GPU之间会通过高速通信（如NVLink）动态地、高效地获取它们所需要的权重部分。</li><li><strong>ZeRO-Offload</strong>: 这是一个强大的“辅助技能”，可以将ZeRO管理的任何部分（优化器状态、梯度、模型权重）从宝贵的GPU显存**卸载（Offload）**到成本更低的CPU内存中，在需要时再加载回显存。这使得在显存有限的硬件上训练超大规模模型成为可能。</li></ul></li></ul><h4 id="_3-训练优化-3d并行-3d-parallelism" tabindex="-1"><a class="header-anchor" href="#_3-训练优化-3d并行-3d-parallelism"><span><strong>3. 训练优化：3D并行（3D Parallelism）</strong></span></a></h4><p>除了ZeRO，DeepSpeed还将已有的并行策略进行了整合和优化，形成了一套完整的“3D并行”方案：</p><ol><li><strong>数据并行 (Data Parallelism)</strong>：多个GPU同时处理不同批次的数据。（“人多力量大”）</li><li><strong>张量并行 (Tensor Parallelism)</strong>：将模型内部的单个大矩阵（如Attention层的大权重矩阵）切分到不同的GPU上进行协同计算。（“把一个大任务拆成几块，大家一起做”）</li><li><strong>流水线并行 (Pipeline Parallelism)</strong>：将模型的不同层（Layers）分配到不同的GPU上，形成一条“流水线”。（“流水线上每个人只负责一道工序”）</li></ol><p>DeepSpeed可以将ZeRO与这三种并行策略巧妙地结合起来，以应对不同规模的模型和硬件集群，最大化训练效率。</p><h4 id="_4-推理优化-deepspeed-inference" tabindex="-1"><a class="header-anchor" href="#_4-推理优化-deepspeed-inference"><span><strong>4. 推理优化：DeepSpeed Inference</strong></span></a></h4><p>当模型训练完成并部署上线时，DeepSpeed同样提供了强大的推理优化功能。</p><ul><li><strong>核心技术</strong>： <ul><li><strong>深度融合 (Deep Fusion)</strong>：将多个计算核（Kernels）融合成一个，减少GPU的计算启动开销。</li><li><strong>高效的计算核</strong>：为Transformer中的关键操作（如LayerNorm、Softmax）提供了高度优化的自定义计算核。</li><li><strong>张量并行推理</strong>：支持与训练时相同的张量并行策略，让多个GPU可以协同完成对一个Prompt的推理，以降低单次请求的延迟。</li><li><strong>动态批处理 (Dynamic Batching)</strong>：智能地将不同时间到达的请求组合成批次进行处理，以提高GPU的利用率和吞吐量。</li></ul></li><li><strong>与vLLM等框架的关系</strong>： <ul><li>DeepSpeed Inference是一个非常强大的推理引擎，但像<strong>vLLM</strong>这样的后起之秀，通过引入<strong>PagedAttention</strong>等更先进的技术，在某些LLM推理场景（特别是高吞吐量）下，可能会表现出更高的性能。</li><li>很多时候，开发者会根据具体模型的特点和业务场景（追求低延迟还是高吞吐），在这类框架中进行选型。</li></ul></li></ul><h4 id="_5-如何使用" tabindex="-1"><a class="header-anchor" href="#_5-如何使用"><span><strong>5. 如何使用？</strong></span></a></h4><p>DeepSpeed通常不是直接在代码中通过<code>import</code>来调用的。它的使用方式更偏向于“配置”和“启动器”。</p><ol><li><strong>编写配置文件</strong>：您需要创建一个JSON格式的配置文件，在里面声明您想使用的优化策略（如ZeRO Stage 3、是否开启Offload、AdamW优化器的参数等）。</li></ol><p><strong>使用启动器</strong>：通过<code>deepspeed</code>这个命令行工具来启动您的Python训练脚本，例如：</p><ol start="2"><li>Bash</li></ol><div class="language-plain line-numbers-mode" data-highlighter="shiki" data-ext="plain" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-plain"><span class="line"><span>deepspeed --num_gpus=8 training_script.py --deepspeed_config ds_config.json</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>DeepSpeed启动器会自动为您处理好多GPU的初始化、并行策略的应用等所有复杂工作。在Hugging Face <code>Trainer</code>中，您也只需要在配置中指定DeepSpeed配置文件的路径即可，集成非常方便。</p><p><strong>总结</strong>：DeepSpeed是一个面向<strong>大规模AI模型</strong>的、功能极其强大的<strong>性能优化库</strong>。它通过ZeRO、3D并行和一系列推理优化技术，将硬件的潜力压榨到极致。当需要微调或部署一个因太大而无法直接在硬件上运行的模型时，或者当希望将训练效率提升一个数量级时，DeepSpeed就是必须掌握的核心工具。</p>',21)]))}const g=n(i,[["render",o]]),d=JSON.parse('{"path":"/tech/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E4%B8%8E%E5%B7%A5%E5%85%B7/DeepSpeed.html","title":"DeepSeed","lang":"zh-CN","frontmatter":{"title":"DeepSeed","date":"2024-12-20T00:00:00.000Z"},"git":{"createdTime":1753758135000,"updatedTime":1753843586000,"contributors":[{"name":"codingXuan","username":"codingXuan","email":"34129858+codingXuan@users.noreply.github.com","commits":3,"url":"https://github.com/codingXuan"}]},"readingTime":{"minutes":4.64,"words":1393},"filePathRelative":"tech/AIGC框架详解/微调训练框架与工具/DeepSpeed.md","excerpt":"<h4><strong>1. 核心定位：大规模AI模型的“超级增压器”</strong></h4>\\n<p>如果说PyTorch是制造发动机的工具箱，那么DeepSpeed就是一套为这款发动机设计的、集成了<strong>涡轮增压、氮气加速、先进冷却系统于一体的“极限性能改装套件”</strong>。</p>\\n<p>它的核心价值在于，让您能够在现有的硬件上，训练和推理更大规模的模型，或者以更高的效率来训练和推理同等规模的模型。它通过在并行计算、内存优化和推理加速等多个维度提供极致的优化来实现这一目标。</p>\\n<h4><strong>2. 训练优化：ZeRO——DeepSpeed的“黑科技”</strong></h4>"}');export{g as comp,d as data};

import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,a as r,o as s}from"./app-BmWXErMj.js";const l={};function g(i,n){return s(),t("div",null,n[0]||(n[0]=[r("<p><strong>1. 指导原则：场景、数据与模型的匹配</strong></p><p>模型评估与迭代的第一步是基于业务的“顶层设计”。其核心原则是实现业务场景、可用数据和模型能力三者之间的最佳匹配。</p><ul><li><strong>场景决定模型架构</strong>： <ul><li><strong>判别式任务</strong>（如意图识别、情感分类）：优先考虑轻量级的BERT、RoBERTa等编码器（Encoder）模型，或传统的机器学习模型（如XGBoost），成本效益高。</li><li><strong>生成式任务</strong>（如多轮对话、文案撰写、代码生成）：需要选择基于Transformer架构的生成式大语言模型（LLM），如GPT系列、Llama系列，或支持MoE（混合专家）架构的模型以提高效率。</li></ul></li><li><strong>数据决定策略与模型规模</strong>： <ul><li><strong>数据量极少（&lt; 1万条）</strong>：<strong>不建议进行微调</strong>。微调很可能导致模型“过拟合”，忘记原有的通用能力。此时最佳策略是 <strong>RAG（检索增强生成）</strong>，将少量高质量数据作为上下文，通过Prompt工程来利用大模型的零样本（Zero-shot）或少样本（Few-shot）能力。</li><li><strong>数据量中等（10万-100万条）</strong>：这是<strong>微调的最佳区间</strong>。可以选择一个合适尺寸的基础模型（如7B、13B，一般不超过30B）进行全量或部分参数微调（如LoRA）。目标是向模型注入领域知识和特定的任务范式。</li><li><strong>数据量巨大（千万级以上）</strong>：具备了进行<strong>持续预训练</strong>（Continual Pre-training）甚至从零开始训练一个模型（Train from Scratch）的潜力。此时需要选择更大参数量的模型（如70B以上）来有效“吸收”海量数据中的知识。</li></ul></li></ul><p><strong>2. 核心环节：科学的量化评估体系</strong></p><p>迭代的基础是评估。没有评估，优化就无从谈起。一个科学的评估体系包含以下部分：</p><ul><li><strong>A. 构建“黄金”评估集</strong>： <ul><li>在项目初期，投入人力构建一个能反映核心业务场景、数据分布均衡、高质量的、规模适中（如1000条）的测试集。</li><li><strong>该数据集在迭代过程中保持不变</strong>，作为衡量所有模型版本优劣的“恒定标尺”。</li></ul></li><li><strong>B. 选择多维度的评估指标</strong>： <ul><li><strong>离线评估</strong>： <ul><li><strong>客观指标</strong>：针对有标准答案的任务，使用精确率、召回率、F1等。</li><li><strong>模型评估</strong>：利用<code>LLM-as-a-Judge</code>，让顶级LLM根据自定义的维度（如“遵循指令”、“逻辑清晰”、“富有创意”）对模型输出进行1-10分的打分。</li></ul></li><li><strong>在线评估</strong>： <ul><li><strong>A/B 测试</strong>：将新旧两个版本的模型同时部署，让它们服务于真实用户，对比点击率、转化率、满意度等真实业务指标。</li><li><strong>人工评估</strong>：由内部的业务专家团队对模型的线上输出进行抽样和评级，这是最可靠但也成本最高的评估方式。</li></ul></li></ul></li></ul><p><strong>3. 迭代过程：持续提纯的循环</strong></p><p>模型的迭代是一个螺旋式上升的、以数据为中心的闭环流程。</p><ul><li><strong>定义</strong>：迭代并非简单地用新数据重新训练，而是在一个已经表现良好的模型版本（<code>v1.0</code>）的基础上，利用新收集到的、高质量的数据（尤其是线上真实场景的“Bad Case”），进行<strong>增量微调（Incremental Fine-tuning）</strong>，从而得到一个更强的模型版本（<code>v1.1</code>）。</li><li><strong>循环流程</strong>： <ol><li><strong>收集数据</strong>：从线上应用、人工标注、数据增强等渠道收集新的高质量数据。</li><li><strong>清洗与标注</strong>：对新数据进行严格的清洗和标注。</li><li><strong>增量微调</strong>：在上一版最优模型的基础上，用新数据进行微调。</li><li><strong>全面评估</strong>：使用“黄金评估集”和多维度指标，科学地评估新模型是否真的比旧模型更好。</li><li><strong>上线部署</strong>：如果评估通过，将新模型部署上线（或进入A/B测试），替换旧模型。</li><li>回到第一步，开始新一轮的循环。</li></ol></li></ul><p>这个过程就像“提纯”一样，每一次循环，模型的领域知识更扎实，对特定任务的理解更深刻，从而不断逼近业务的理想状态。</p>",10)]))}const u=o(l,[["render",g]]),c=JSON.parse('{"path":"/tech/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E8%BF%AD%E4%BB%A3.html","title":"模型评估与迭代","lang":"zh-CN","frontmatter":{"title":"模型评估与迭代","date":"2024-06-20T00:00:00.000Z"},"git":{"createdTime":1753758135000,"updatedTime":1753843586000,"contributors":[{"name":"codingXuan","username":"codingXuan","email":"34129858+codingXuan@users.noreply.github.com","commits":3,"url":"https://github.com/codingXuan"}]},"readingTime":{"minutes":3.62,"words":1085},"filePathRelative":"tech/AIGC应用层建设思路/模型评估与迭代.md","excerpt":"<p><strong>1. 指导原则：场景、数据与模型的匹配</strong></p>\\n<p>模型评估与迭代的第一步是基于业务的“顶层设计”。其核心原则是实现业务场景、可用数据和模型能力三者之间的最佳匹配。</p>\\n<ul>\\n<li><strong>场景决定模型架构</strong>：\\n<ul>\\n<li><strong>判别式任务</strong>（如意图识别、情感分类）：优先考虑轻量级的BERT、RoBERTa等编码器（Encoder）模型，或传统的机器学习模型（如XGBoost），成本效益高。</li>\\n<li><strong>生成式任务</strong>（如多轮对话、文案撰写、代码生成）：需要选择基于Transformer架构的生成式大语言模型（LLM），如GPT系列、Llama系列，或支持MoE（混合专家）架构的模型以提高效率。</li>\\n</ul>\\n</li>\\n<li><strong>数据决定策略与模型规模</strong>：\\n<ul>\\n<li><strong>数据量极少（&lt; 1万条）</strong>：<strong>不建议进行微调</strong>。微调很可能导致模型“过拟合”，忘记原有的通用能力。此时最佳策略是 <strong>RAG（检索增强生成）</strong>，将少量高质量数据作为上下文，通过Prompt工程来利用大模型的零样本（Zero-shot）或少样本（Few-shot）能力。</li>\\n<li><strong>数据量中等（10万-100万条）</strong>：这是<strong>微调的最佳区间</strong>。可以选择一个合适尺寸的基础模型（如7B、13B，一般不超过30B）进行全量或部分参数微调（如LoRA）。目标是向模型注入领域知识和特定的任务范式。</li>\\n<li><strong>数据量巨大（千万级以上）</strong>：具备了进行<strong>持续预训练</strong>（Continual Pre-training）甚至从零开始训练一个模型（Train from Scratch）的潜力。此时需要选择更大参数量的模型（如70B以上）来有效“吸收”海量数据中的知识。</li>\\n</ul>\\n</li>\\n</ul>"}');export{u as comp,c as data};

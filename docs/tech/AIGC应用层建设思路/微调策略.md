---
title: 微调策略
date: 2024-06-12
---

#### **1. 微调的目标与定位**
在上一篇文章中，我分享了对微调的理解。微调是在预训练模型的基础上，针对垂直领域进行特定任务的训练，或者可以理解为使用自身数据来进一步优化模型，使其更好地适应特定业务场景。这个过程的核心在于通过调整一系列关键参数和策略，来引导模型学习新的知识和行为范式。

#### **2. 微调策略的核心支柱**
一个成功的微调任务，可以从三个核心支柱来进行顶层设计：

+ **A. 数据策略**：定义了模型“学什么”。这包括如何准备、清洗和组织训练数据，以及如何设定输入输出的长度限制等。
+ **B. 优化策略**：定义了模型“怎么学”。这涉及到学习率、批次大小、优化器等超参数的选择，它们共同决定了模型参数更新的数学过程。
+ **C. 训练策略**：定义了“如何保障学习过程顺利进行”。这涉及到训练的步数/轮次、模型的保存与评估机制、以及使用何种分布式或加速技术（如DeepSpeed）等工程层面的配置。

#### **3. 深度解析：关键超参数与优化器**
##### **A. 学习率与调度器 (Learning Rate & Scheduler)**
学习率是控制模型每次更新时参数变化幅度的关键参数。

+ **核心作用**：在调整学习率时，会参考 `loss` 值。如果训练初期的 `loss` 收敛太慢，我会适当提高学习率；如果 `loss` 波动较大，则会降低学习率。一般来说，较低的学习率可以确保模型的稳步调整，避免“学过头”。
+ **深度拓展：学习率调度器 (Scheduler)** 在实践中，学习率很少保持不变。使用**学习率调度器**是提升训练效果的标配。最经典的策略是 **“预热+余弦衰减”**：
    1. **预热 (Warmup)**：在训练最开始的几步，使用一个极低的学习率，然后线性地增加到设定的初始值（如 `2e-5`）。这能帮助模型在训练初期更稳定地适应新数据。
    2. **衰减 (Decay)**：预热期结束后，学习率会按照余弦曲线缓慢下降。这使得模型在训练后期能够以更小的步长进行微调，从而更精细地收敛到最优点。

##### **B. 批次大小与梯度累积 (Batch Size & Gradient Accumulation)**
批次大小指的是每次训练“喂”给模型的数据量。

+ **核心作用**：较小的批次可以帮助模型稳定训练，常见配置为16或32。当算力有限时，调整批次大小尤为重要；如果算力充足，批次越大，训练速度越快。
+ **深度拓展：有效批次大小与梯度累积** 当显存不足以支持一个理想的大批次时，**梯度累积**是应对的利器。它允许我们通过多次计算小批次的梯度并将其累加，来模拟一次大批次的训练效果。
    - **有效批次大小公式**：`Effective Batch Size = per_device_train_batch_size * num_gpus * gradient_accumulation_steps`
    - 通过调整 `gradient_accumulation_steps`，您可以在不增加显存消耗的情况下，实现大批次训练，这有助于稳定训练过程。

##### **C. 训练轮次 (Epochs vs. Max Steps)**
+ **Epoch**：指模型完整遍历一次整个训练数据集的次数。
+ **Max Steps**：指模型总共执行参数更新的步数。
+ **选择建议**：对于大小固定的中小型数据集，使用`Epochs`更直观。对于流式读取或规模极其庞大的数据集，使用`Max Steps`作为训练的终止条件是更合适的做法。

##### **D. 权重衰减与优化器 (Weight Decay & Optimizer)**
+ **权重衰减 (Weight Decay)**：这是一种经典的正则化策略，用于防止模型过拟合。它通过对损失函数增加一个与权重大小相关的惩罚项，来限制模型权重变得过大，从而使得模型更简单、泛化能力更强。通常，AdamW优化器的默认值`0.01`是一个很好的起点，一般无需调整。
+ **优化器 (Optimizer)**：`AdamW`是目前LLM微调中最常用、最稳健的优化器。它在传统Adam优化器的基础上，修正了权重衰减的实现方式，使其在现代深度学习任务中效果更好。

#### **4. 参数高效微调 (PEFT)**
除了上述传统的全量微调（SFT），为了极大地降低微调对算力的要求，**参数高效微调（PEFT）**已成为当前的主流。

+ **核心思想**：在微调时，冻结（freeze）预训练模型99.9%以上的参数，只训练极小一部分新增的或指定的参数。
+ **主流方法：LoRA (Low-Rank Adaptation)**
    - **原理**：在模型的关键层（如Attention层）旁边，注入两个小型的、可训练的“适配器”矩阵。训练时，所有原始权重都保持不变，只有这些适配器的参数会被更新。
    - **优势**：
        1. **显存需求锐减**：使得在单张消费级显卡上微调大模型成为可能。
        2. **训练速度提升**：需要计算和存储的梯度大大减少。
        3. **部署极其灵活**：微调产物只是几十兆（MB）的适配器文件，一个基础模型可以搭配多个不同任务的适配器，实现快速切换。
+ **极致优化：QLoRA (Quantized LoRA)**
    - **原理**：在应用LoRA之前，先将整个冻结的模型权重**量化**（**Quantize**）成4-bit的超低精度格式，进一步把显存占用压缩到极致。
    - **效果**：使得在单张24GB显存的显卡上，微调70B（700亿参数）甚至更大规模的模型都成为了现实。

#### **5. 实践：SFT训练配置示例与解读**
以下是一个典型的SFT训练配置文件。

YAML

```plain
data_config:
  train_file: train.jsonl         # 训练文件路径
  val_file: dev.jsonl             # 验证文件路径，用于在训练过程中评估模型性能，防止过拟合
  num_proc: 4                     # 数据预处理时使用的并行进程数

max_input_length: 256             # 输入最大长度，超出部分将被截断
max_output_length: 512            # 输出最大长度

training_args:
  output_dir: ./output            # 训练产物（模型检查点、日志等）的保存路径
  max_steps: 3000                 # 最大训练步数。与epoch二选一，用于控制训练时长
  learning_rate: 2e-5             # 初始学习率，通常会配合学习率调度器使用
  per_device_train_batch_size: 1  # 每个GPU的单次训练批次大小
  # gradient_accumulation_steps: 8  # 梯度累积步数，有效批次大小为 1 * 卡数 * 8
  dataloader_num_workers: 16      # 数据加载时使用的并行线程数，加速数据读取
  remove_unused_columns: false    # 是否移除数据集中模型不需要的列，通常保持false
  
  save_strategy: steps            # 模型保存策略，可设为 'steps' 或 'epoch'
  save_steps: 500                 # 每隔500步保存一次模型检查点
  
  log_level: info                 # 日志级别
  logging_strategy: steps         # 日志记录策略
  logging_steps: 10               # 每隔10步在控制台打印一次loss等信息
  
  evaluation_strategy: steps      # 评估策略，与save_strategy配合使用
  eval_steps: 500                 # 每隔500步在验证集上进行一次评估
  
  predict_with_generate: true     # 在评估时使用生成模式，适用于文本生成任务
  deepspeed: configs/ds_zero_3.json # 引入DeepSpeed进行分布式训练和内存优化
```

#### **6. 结语**
微调配置项决定了模型训练的关键行为。常见的调整参数如 `learning_rate`、`max_steps`、`per_device_train_batch_size` 对训练效果和速度都有显著影响。在掌握了PEFT等前沿技术后，我们能以更低的成本进行实验。但最终的“最优解”没有捷径，需要通过大量的、有条理的实验来逐步寻找。


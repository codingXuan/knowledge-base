---
title: rag
date: 2025-06-28  
---

#### **1. RAG的数据结构设计：为精准检索奠定基石**
构建一个健壮的RAG系统的第一步，是设计一个优秀的、信息丰富的**数据结构**。我们存入向量数据库的，不应该仅仅是“文本块+向量”，而是一个结构化的**“数据节点（Node/Chunk）”**。

**一个理想的数据节点Schema应包含：**

| 字段名 | 类型 | 描述 | 示例 |
| --- | --- | --- | --- |
| `chunk_id` | String (UUID) | **唯一的块ID**。用于精确引用和更新。 | `“c1a2b3d4-…”` |
| `content` | String | **文本块原文**。这是将要被Embedding和提供给LLM的核心内容。 | `“RAG的核心是检索...”` |
| `vector` | Array[Float] | **文本块的向量表示**。由Embedding模型生成。 | `[0.12, -0.45, ...]` |
| `metadata` | Object/JSON | **丰富的元数据**。这是实现高级功能的关键，必须精心设计。 | (见下方详细示例) |




`**metadata**`** 示例：**

```plain
{
  "source_type": "PDF",
  "source_id": "doc_xyz_123", // 原始文档的唯一ID
  "document_title": "初始阶段第一次治疗话术.pdf",
  "page_number": 42,
  "chunk_sequence_in_doc": 105, // 这是该文档中的第105个块
  "author": "xxx",
  "creation_date": "2025-04-15",
  "security_level": "CONFIDENTIAL",
  "tags": ["finance", "quarterly_report", "Q1"],
  "keywords": ["求治原因", "人际关系圈", "抑郁症"] // 可选，通过LLM提取
}
```

**为什么这个结构很重要？**

+ **精准过滤**：您可以在向量搜索前或搜索后，根据元数据进行过滤（例如，`source_type == 'PDF' AND page_number > 10`），极大地缩小检索范围，提升精准度。
+ **可溯源性**：当LLM根据某个Chunk生成答案时，您可以利用元数据（如文件名、页码）向用户展示**答案的来源**，增强应用的可信度。
+ **可维护性**：当原始文档更新时，可以通过`source_id`快速找到并更新或删除所有相关的Chunks。

#### **2. RAG的评测与埋点：衡量系统的“好”与“坏”**
“埋点”是为了收集数据，而数据是为了评测。一个没有评测体系的RAG系统，其优化过程如同“闭门造车”。

**A. 离线评测（上线前）** 在开发阶段，我们需要一套“黄金评估集”来衡量RAG系统的核心组件——**检索器（Retriever）**的性能。

+ **核心评测指标**：
    - **命中率 (Hit Rate)**：对于一个问题，我们期望的答案是否出现在了召回的Top-K个文档中？
    - **平均倒数排名 (Mean Reciprocal Rank, MRR)**：衡量的是我们找到的第一个相关文档的排名的倒数。这个指标越接近1，说明系统能越快地找到正确答案。
    - **归一化折损累计增益 (nDCG)**：一个更复杂的指标，它不仅考虑是否命中，还考虑了相关文档的排名位置，排名越靠前得分越高。

**B. 在线评测（上线后，即“埋点”）** 当系统上线后，我们需要通过埋点来收集真实的用户行为和系统数据，以进行持续的迭代。

+ **需要埋点记录的核心数据**：
    - **用户输入**：`query` (用户的问题)
    - **检索结果**：`retrieved_chunks` (召回的文本块原文、ID和相关性分数)
    - **生成结果**：`generated_answer` (LLM最终生成的答案)
    - **用户反馈**：
        * **显式反馈**：**“顶/踩”**按钮、**“答案是否有用？”**的评分、用户主动提交的**“复制答案”**事件。
        * **隐式反馈**：用户是否在得到答案后继续追问、是否修改了问题重新搜索。
    - **系统性能**：`retrieval_latency` (检索耗时), `generation_latency` (生成耗时)。

通过分析这些埋点数据，可以回答诸如“哪些类型的问题检索效果不好？”、“用户对哪些答案不满意？”等关键问题，从而找到迭代的方向。

#### **3. RAG的核心策略与方法选择**
一个基础的RAG流程（切块->编码->检索->生成）只是起点。要打造SOTA级别的系统，需要采用更高级的策略。

| 策略类别 | 具体方法 | 解决什么问题 | 何时选择 |
| --- | --- | --- | --- |
| **基础RAG (Naive RAG)** | 简单的“检索-生成” | 快速搭建原型，验证基本流程。 | **项目启动时**，作为性能基线（Baseline）。 |
| **高级检索 (Advanced Retrieval)** | **1. 混合搜索 (Hybrid Search)**    **2. 重排序 (Re-ranking)** | 1. 召回不足，语义和关键词都想要。   2. 召回结果多但不够精准，“噪音”太多。 | 1. 当用户问题中包含大量**专有名词、ID、代码**时。   2. 当对检索的**精准度（Precision）有极高要求时。 |
| 高级索引 (Advanced Indexing) | 1. 父文档检索器 (Parent Document Retriever)    2. 多表示索引 (Multi-Representation Indexing) | 1. 检索到的上下文太短，LLM理解不全面。   2. 用户问题角度多变，单一向量无法覆盖。 | 1. 当需要为LLM提供更完整上下文**时。   ****2. 当文档包含**摘要、标题、表格**等多种形式的内容时。 |
| **高级生成 (Advanced Generation)** | **1. 查询转换 (Query Transformation)**    **2. 上下文压缩 (Contextual Compression)** | 1. 用户问题模糊、不规范，直接检索效果差。   2. 召回的上下文太长或有冗余，超出LLM窗口或增加成本。 | 1. 当发现大量用户查询是**口语化或不完整**的。   2. 当需要**极致优化Token成本**或处理长文档时。 |




**决策流程建议**：

1. **从基础RAG开始**，并建立好评测和埋点体系。
2. 分析评测结果和线上数据，**定位瓶颈**。
3. **如果检索结果不精准** -> 优先引入 **Re-ranking**。
4. **如果检索结果经常“漏掉”正确答案** -> 尝试 **Hybrid Search**。
5. **如果检索到的上下文信息不足** -> 尝试 **Parent Document Retriever**。
6. **如果用户问题质量不高** -> 尝试 **Query Transformation**。

**总结**：构建一个生产级的RAG系统，是一个从**数据结构设计**出发，以**评测与埋点**为罗盘，通过不断实验和迭代，逐步叠加**高级策略**的系统工程。清晰的数据结构是基础，科学的评测体系是导航，而丰富的策略库则是达成目标的工具箱。


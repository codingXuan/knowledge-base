---
title: DeepSeed
---

#### **1. 核心定位：大规模AI模型的“超级增压器”**
如果说PyTorch是制造发动机的工具箱，那么DeepSpeed就是一套为这款发动机设计的、集成了**涡轮增压、氮气加速、先进冷却系统于一体的“极限性能改装套件”**。

它的核心价值在于，让您能够在现有的硬件上，训练和推理更大规模的模型，或者以更高的效率来训练和推理同等规模的模型。它通过在并行计算、内存优化和推理加速等多个维度提供极致的优化来实现这一目标。

#### **2. 训练优化：ZeRO——DeepSpeed的“黑科技”**
ZeRO（Zero Redundancy Optimizer，零冗余优化器）是DeepSpeed名声大噪的独门秘籍，它主要用于解决训练过程中显存（VRAM）不足的问题。

+ **问题的根源**：在标准的**数据并行（Data Parallelism）**训练中，每个GPU都会加载一份完整的模型权重、一份完整的梯度、以及一份完整的优化器状态。对于一个大型模型来说，这三者的副本会占据海量的显存，成为最大的瓶颈。
+ **ZeRO的解决方案（分阶段进行）**：
    - **Stage 1**: **分割优化器状态 (Partitioning Optimizer States)**。不再让每个GPU都保留完整的优化器状态，而是将其切分，每个GPU只保留一部分。这能显著减少显存占用。
    - **Stage 2**: **分割梯度 (Partitioning Gradients)**。在Stage 1的基础上，进一步将梯度的存储也进行切分。
    - **Stage 3**: **分割模型权重 (Partitioning Model Weights)**。这是最彻底的阶段，连模型权重本身也进行切分，每个GPU只拥有模型的一部分。在需要进行前向或反向传播时，GPU之间会通过高速通信（如NVLink）动态地、高效地获取它们所需要的权重部分。
    - **ZeRO-Offload**: 这是一个强大的“辅助技能”，可以将ZeRO管理的任何部分（优化器状态、梯度、模型权重）从宝贵的GPU显存**卸载（Offload）**到成本更低的CPU内存中，在需要时再加载回显存。这使得在显存有限的硬件上训练超大规模模型成为可能。

#### **3. 训练优化：3D并行（3D Parallelism）**
除了ZeRO，DeepSpeed还将已有的并行策略进行了整合和优化，形成了一套完整的“3D并行”方案：

1. **数据并行 (Data Parallelism)**：多个GPU同时处理不同批次的数据。（“人多力量大”）
2. **张量并行 (Tensor Parallelism)**：将模型内部的单个大矩阵（如Attention层的大权重矩阵）切分到不同的GPU上进行协同计算。（“把一个大任务拆成几块，大家一起做”）
3. **流水线并行 (Pipeline Parallelism)**：将模型的不同层（Layers）分配到不同的GPU上，形成一条“流水线”。（“流水线上每个人只负责一道工序”）

DeepSpeed可以将ZeRO与这三种并行策略巧妙地结合起来，以应对不同规模的模型和硬件集群，最大化训练效率。

#### **4. 推理优化：DeepSpeed Inference**
当模型训练完成并部署上线时，DeepSpeed同样提供了强大的推理优化功能。

+ **核心技术**：
    - **深度融合 (Deep Fusion)**：将多个计算核（Kernels）融合成一个，减少GPU的计算启动开销。
    - **高效的计算核**：为Transformer中的关键操作（如LayerNorm、Softmax）提供了高度优化的自定义计算核。
    - **张量并行推理**：支持与训练时相同的张量并行策略，让多个GPU可以协同完成对一个Prompt的推理，以降低单次请求的延迟。
    - **动态批处理 (Dynamic Batching)**：智能地将不同时间到达的请求组合成批次进行处理，以提高GPU的利用率和吞吐量。
+ **与vLLM等框架的关系**：
    - DeepSpeed Inference是一个非常强大的推理引擎，但像**vLLM**这样的后起之秀，通过引入**PagedAttention**等更先进的技术，在某些LLM推理场景（特别是高吞吐量）下，可能会表现出更高的性能。
    - 很多时候，开发者会根据具体模型的特点和业务场景（追求低延迟还是高吞吐），在这类框架中进行选型。

#### **5. 如何使用？**
DeepSpeed通常不是直接在代码中通过`import`来调用的。它的使用方式更偏向于“配置”和“启动器”。

1. **编写配置文件**：您需要创建一个JSON格式的配置文件，在里面声明您想使用的优化策略（如ZeRO Stage 3、是否开启Offload、AdamW优化器的参数等）。

**使用启动器**：通过`deepspeed`这个命令行工具来启动您的Python训练脚本，例如：

2. Bash

```plain
deepspeed --num_gpus=8 training_script.py --deepspeed_config ds_config.json
```

DeepSpeed启动器会自动为您处理好多GPU的初始化、并行策略的应用等所有复杂工作。在Hugging Face `Trainer`中，您也只需要在配置中指定DeepSpeed配置文件的路径即可，集成非常方便。

**总结**：DeepSpeed是一个面向**大规模AI模型**的、功能极其强大的**性能优化库**。它通过ZeRO、3D并行和一系列推理优化技术，将硬件的潜力压榨到极致。当需要微调或部署一个因太大而无法直接在硬件上运行的模型时，或者当希望将训练效率提升一个数量级时，DeepSpeed就是必须掌握的核心工具。


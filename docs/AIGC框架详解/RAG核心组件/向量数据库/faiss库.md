---
title: faiss库
---

#### **1. 核心定位：向量检索的“高性能计算引擎”**
Faiss (Facebook AI Similarity Search) 是由 **Facebook AI Research（现Meta AI）开发的、一个专注于高性能向量相似度搜索**的**开源库（Library）**。

最核心的认知是：**Faiss不是一个数据库，而是一个算法库。**

我们可以用一个比喻来理解它和向量数据库的关系：

+ **Faiss**：如同汽车里那台经过极致性能优化的**“V12发动机”**。它的唯一职责就是以最快的速度进行核心计算（向量相似度搜索），它本身不带轮子、方向盘或车身。
+ **ChromaDB / Milvus**：则是一辆**“完整的汽车”**。这辆汽车的心脏可能就是一台类似Faiss的发动机，但它还提供了方向盘（API接口）、车身（数据管理）、油箱（持久化存储）、轮胎（网络服务）等所有部件，让可以直接“驾驶”。

#### **2. “库” vs. “数据库”：一个关键的区别**
| 特性 | **Faiss (库 / Library)** | **ChromaDB / Milvus (数据库 / Database)** |
| --- | --- | --- |
| **核心职责** | 提供**在内存中**进行高效向量搜索的算法实现。 | 提供一个**完整的、可独立运行的服务**，用于管理、存储、检索数据。 |
| **数据管理** | **不负责**。需要自己管理原始文本、元数据，并维护ID和向量之间的映射关系。 | **负责**。内置了数据管理系统，支持向量、文本和元数据的增删改查（CRUD）。 |
| **持久化** | **不自动处理**。它是一个纯内存的工具，需要自己手动将构建好的索引（Index）序列化并保存到磁盘文件中，下次使用时再手动加载。 | **自动处理**。拥有自己的存储引擎，数据写入后会自动持久化到磁盘，保证了数据的可靠性。 |
| **服务模式** | **嵌入式**。它作为Python程序的一部分被直接调用。 | **客户端-服务器模式**。它作为一个独立的服务运行，的应用通过网络API来访问它。 |
| **功能范畴** | **专注**于向量的ANN（近似最近邻）搜索算法。 | **全面**，除了向量搜索，还提供过滤、混合搜索、扩缩容、权限管理等。 |




**结论**：不能像连接MySQL一样去“连接”Faiss。是在的代码中 `import faiss`，然后像使用一个工具函数一样去调用它的功能。

#### **3. Faiss是如何工作的？核心概念**
Faiss的强大之处在于它提供了极其丰富的索引（Index）类型，让开发者可以在**搜索速度、内存占用和搜索精度**这三者之间做出精细的权衡。

+ `**Index**`** 对象**：这是Faiss的核心。可以把它想象成一个专门为向量搜索优化过的数据结构。将向量“添加”到这个Index中，然后就可以用它来进行高效的搜索。
+ **几种关键的索引类型**：
    1. `**IndexFlatL2**`** (精确索引)**
        * **原理**：暴力搜索。它会计算查询向量与索引中每一个向量之间的真实距离，然后返回最接近的几个。
        * **特点**：结果100%准确，但当数据量巨大时，搜索速度会非常慢。适合作为评估其他索引精度的“黄金标准”。
    2. `**IndexIVFFlat**`** (倒排文件索引)**
        * **原理**：这是最经典的近似搜索算法之一。它会先将整个向量空间通过聚类（如k-means）划分成若干个“区域”（Cells）。搜索时，它会先定位到查询向量所在的几个邻近区域，然后只在这几个小区域内进行暴力搜索。
        * **特点**：通过缩小搜索范围，极大地提升了搜索速度。它需要在添加向量之前，先用一部分代表性数据对索引进行**“训练（train）”**，以完成空间的划分。
    3. `**IndexHNSWFlat**`** (图索引)**
        * **原理**：基于“六度空间”理论，通过构建一个多层的、导航式的图结构来连接所有向量。搜索时，从一个粗糙的顶层图开始，像导航一样，一步步跳跃到越来越精确的图层，最终在底层图中找到最近的邻居。
        * **特点**：这是当前性能最好、应用最广的近似搜索算法之一，在速度和精度的平衡上做得非常出色。

#### **4. Faiss的典型工作流（Python示例）**
Python

```plain
import numpy as np
import faiss

# 0. 准备数据
d = 64      # 向量维度
nb = 100000 # 数据集大小
nq = 10000  # 查询向量数量

# 创建一些随机的向量数据
np.random.seed(1234)
xb = np.random.random((nb, d)).astype('float32')
xq = np.random.random((nq, d)).astype('float32')


# 1. 选择并构建索引 (以IndexIVFFlat为例)
nlist = 100  # 我们将空间划分为100个区域
quantizer = faiss.IndexFlatL2(d)  # 使用一个基础的精确索引来定义区域
index = faiss.IndexIVFFlat(quantizer, d, nlist)


# 2. 训练索引 (Training) - 只有部分索引类型需要这一步
# Faiss需要学习数据的分布，以完成空间划分
print("Is index trained?", index.is_trained) # False
index.train(xb)
print("Is index trained?", index.is_trained) # True


# 3. 添加向量到索引 (Adding)
index.add(xb)
print("Total vectors in index:", index.ntotal) # 100000


# 4. 执行搜索 (Searching)
k = 4  # 我们想为每个查询向量找到4个最近邻
D, I = index.search(xq, k)  # D是距离，I是索引ID

print("Search results shape:", I.shape) # (10000, 4)
print("First 5 results:\n", I[:5])


# 5. 手动持久化 (Saving and Loading)
# Faiss不自动保存，需要手动将内存中的索引写入文件
faiss.write_index(index, "my_index.faiss")

# 下次使用时，可以从文件加载
index_loaded = faiss.read_index("my_index.faiss")
print("Loaded index has total vectors:", index_loaded.ntotal)
```

**总结**：Faiss是向量检索领域一个无与伦比的、专注于性能的**底层计算库**。它为上层应用（包括许多向量数据库）提供了核心的ANN搜索能力。当需要在一个已经定义好的向量集合上，进行极致的、内存内的相似度搜索时，Faiss是的不二之选。而当需要一个完整的、包含数据管理和服务的解决方案时，就应该选择像ChromaDB或Milvus这样的**向量数据库**。


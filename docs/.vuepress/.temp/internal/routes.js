export const redirects = JSON.parse("{}")

export const routes = Object.fromEntries([
  ["/", { loader: () => import(/* webpackChunkName: "index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/index.html.js"), meta: {"excerpt":"\n<p>欢迎来到我的个人知识库。</p>\n<p>这里整理了关于 AIGC、RAG、模型微调等方向的学习笔记和实践总结。</p>\n","readingTime":{"minutes":0.14,"words":43},"title":"我的 AI 知识库","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/", { loader: () => import(/* webpackChunkName: "AIGC框架详解_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/index.html.js"), meta: {"excerpt":"\n<p>AIGC框架详解随笔</p>\n","readingTime":{"minutes":0.04,"words":12},"title":"AIGC框架详解","type":"article"} }],
  ["/%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1%E4%B8%8E%E9%83%A8%E7%BD%B2/", { loader: () => import(/* webpackChunkName: "推理服务与部署_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/推理服务与部署/index.html.js"), meta: {"excerpt":"\n","readingTime":{"minutes":0.03,"words":10},"title":"推理与服务与部署简介","type":"article"} }],
  ["/%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1%E4%B8%8E%E9%83%A8%E7%BD%B2/TGI.html", { loader: () => import(/* webpackChunkName: "推理服务与部署_TGI.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/推理服务与部署/TGI.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：Hugging Face官方出品的“生产级”推理解决方案</strong></h4>\n<p>TGI (Text Generation Inference) 是一个专门为大规模语言模型设计的、功能全面且经过生产环境严苛考验的推理服务器。</p>\n<p>作为Hugging Face的“亲儿子”，它的首要目标就是为<strong>Hugging Face Hub</strong>上数以万计的Transformer模型，提供一个官方的、开箱即用的、高性能的部署方案。它被广泛地应用于Hugging Face自己的产品中，如HuggingChat和Inference API服务，其稳定性和可靠性得到了充分验证。</p>","readingTime":{"minutes":4.19,"words":1258},"title":"TGI","type":"article"} }],
  ["/%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1%E4%B8%8E%E9%83%A8%E7%BD%B2/vLLM.html", { loader: () => import(/* webpackChunkName: "推理服务与部署_vLLM.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/推理服务与部署/vLLM.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：LLM推理的“高吞吐量引擎”</strong></h4>\n<p>vLLM是一个由<strong>加州大学伯克利分校（UC Berkeley）的研究人员开发的、专注于提升LLM推理吞吐量（Throughput）和GPU利用率</strong>的开源库。</p>\n<p>我们可以用一个餐厅厨房的类比来理解它的价值：</p>\n<ul>\n<li><strong>传统的推理框架</strong>：像一个混乱的厨房。厨师（GPU）一次只能炒一桌菜（一个批次），并且必须等这桌所有菜都上齐（批次里最慢的请求完成），才能开始下一桌。如果某个客人点菜快、吃得快（短请求），他也得等着同桌吃得最慢的客人，导致厨师（GPU）大部分时间在<strong>空闲等待</strong>。</li>\n<li><strong>vLLM</strong>：则是一个配备了<strong>智能调度系统</strong>的现代化中央厨房。系统（vLLM）能源源不断地、见缝插针地给厨师（GPU）派发新的炒菜任务（新请求），确保厨师<strong>永远处于忙碌状态</strong>，极大地提升了出菜的总效率（吞吐量）。</li>\n</ul>","readingTime":{"minutes":4.47,"words":1342},"title":"vLLM","type":"article"} }],
  ["/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%B1%87%E6%80%BB/", { loader: () => import(/* webpackChunkName: "数据结构汇总_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/数据结构汇总/index.html.js"), meta: {"excerpt":"\n<p>微调、训练、rag等需要的数据结构随笔</p>\n","readingTime":{"minutes":0.09,"words":28},"title":"微调、训练、rag等需要的数据结构","type":"article"} }],
  ["/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%B1%87%E6%80%BB/pt_ft.html", { loader: () => import(/* webpackChunkName: "数据结构汇总_pt_ft.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/数据结构汇总/pt_ft.html.js"), meta: {"excerpt":"<h4><strong>Part 1: 继续预训练 (Continued Pre-training, PT)</strong></h4>\n<p><strong>1. 核心目标：知识灌输 (Knowledge Infusion)</strong></p>\n<ul>\n<li><strong>一句话概括</strong>：让模型成为一个**“特定领域的书呆子”**。</li>\n<li><strong>详细描述</strong>：继续预训练的目标，是向一个已经具备通用知识的LLM（如Qwen），注入<strong>大量特定领域的专业知识和语言风格</strong>。例如，让它学习海量的医学文献、法律文书或公司内部的技术文档。这个过程并不教模型如何“对话”，而是让它熟悉这个领域的词汇、概念、实体关系和叙事方式，使其语言模型的基础概率分布更贴近该领域。</li>\n</ul>","readingTime":{"minutes":5,"words":1499},"title":"pt_ft","type":"article"} }],
  ["/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%B1%87%E6%80%BB/rag.html", { loader: () => import(/* webpackChunkName: "数据结构汇总_rag.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/数据结构汇总/rag.html.js"), meta: {"excerpt":"<h4><strong>1. RAG的数据结构设计：为精准检索奠定基石</strong></h4>\n<p>构建一个健壮的RAG系统的第一步，是设计一个优秀的、信息丰富的<strong>数据结构</strong>。我们存入向量数据库的，不应该仅仅是“文本块+向量”，而是一个结构化的**“数据节点（Node/Chunk）”**。</p>\n<p><strong>一个理想的数据节点Schema应包含：</strong></p>\n<table>\n<thead>\n<tr>\n<th>字段名</th>\n<th>类型</th>\n<th>描述</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>chunk_id</code></td>\n<td>String (UUID)</td>\n<td><strong>唯一的块ID</strong>。用于精确引用和更新。</td>\n<td><code>“c1a2b3d4-…”</code></td>\n</tr>\n<tr>\n<td><code>content</code></td>\n<td>String</td>\n<td><strong>文本块原文</strong>。这是将要被Embedding和提供给LLM的核心内容。</td>\n<td><code>“RAG的核心是检索...”</code></td>\n</tr>\n<tr>\n<td><code>vector</code></td>\n<td>Array[Float]</td>\n<td><strong>文本块的向量表示</strong>。由Embedding模型生成。</td>\n<td><code>[0.12, -0.45, ...]</code></td>\n</tr>\n<tr>\n<td><code>metadata</code></td>\n<td>Object/JSON</td>\n<td><strong>丰富的元数据</strong>。这是实现高级功能的关键，必须精心设计。</td>\n<td>(见下方详细示例)</td>\n</tr>\n</tbody>\n</table>","readingTime":{"minutes":4.93,"words":1480},"title":"rag","type":"article"} }],
  ["/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%B1%87%E6%80%BB/rlhf_dpo.html", { loader: () => import(/* webpackChunkName: "数据结构汇总_rlhf_dpo.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/数据结构汇总/rlhf_dpo.html.js"), meta: {"excerpt":"<h4><strong>1. 核心目标：对齐（Alignment）——让模型更像“人”</strong></h4>\n<p>在完成了**继续预训练（PT，学习知识）<strong>和</strong>指令微调（SFT，学习遵循指令）**之后，模型已经具备了强大的能力。但此时的模型可能还存在一些问题：</p>\n<ul>\n<li>它可能会生成一些无害但无用的“废话”。</li>\n<li>它的回答可能过于“机械”，缺乏真诚和共情。</li>\n<li>在面对模棱两可的问题时，它不知道哪种风格的回答更受人类欢迎。</li>\n</ul>\n<p><strong>RLHF/DPO</strong>的目标，就是解决这个“好不好”的问题。它通过学习人类的<strong>偏好（Preference）数据，将模型的价值观和行为准则，与人类的期望进行对齐（Alignment）</strong>，使其变得更<strong>有用（Helpful）、诚实（Honest）和无害（Harmless）</strong>。</p>","readingTime":{"minutes":4.83,"words":1450},"title":"rlhf_dpo","type":"article"} }],
  ["/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF.html", { loader: () => import(/* webpackChunkName: "AIGC应用层建设思路_AIGC应用层建设思路.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC应用层建设思路/AIGC应用层建设思路.html.js"), meta: {"excerpt":"<h4>ai应用建设思路。</h4>\n<p>在没有算法支持的情况下，构建AI应用，我认为必须具备以下三个核心要素：</p>\n<ol>\n<li><strong>强大的开源或闭源模型</strong></li>\n<li><strong>高质量的数据</strong></li>\n<li><strong>有效的超参数微调方法</strong></li>\n</ol>\n<p>目前市面上的开源模型大多基于具备普适性的大众数据进行训练。然而，企业所需的应用层模型往往涉及更为专业的数据和知识，这些领域的认知是通用模型难以全面理解的。例如，虽然开源模型可以正确回答“心理学是什么学科”，但如果询问关于医学领域的IPT（整合心理治疗），它可能会无法理解或给出错误的回答。因此，按照我的理解，构建AIGC应用的首要任务是收集相关领域的专业知识，并搭建知识库或向量库（即RAG），以便AI能够掌握这些特定的概念。</p>","readingTime":{"minutes":2.35,"words":706},"title":"AIGC应用层建设思路","type":"article"} }],
  ["/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/RAG%E5%BB%BA%E8%AE%BE.html", { loader: () => import(/* webpackChunkName: "AIGC应用层建设思路_RAG建设.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC应用层建设思路/RAG建设.html.js"), meta: {"excerpt":"<h4><strong>1. 核心理念：为LLM配备一个可检索的“长期记忆”</strong></h4>\n<p>RAG（Retrieval-Augmented Generation，检索增强生成）是一种将**信息检索（Retrieval）<strong>与</strong>文本生成（Generation）**相结合的强大架构。其核心理念是，在让大语言模型（LLM）回答问题或执行任务之前，先从一个外部的、可信的知识库中检索出最相关的信息片段，并将这些信息作为上下文（Context）一并提供给LLM。</p>\n<p>这种方式的优势在于：</p>\n<ul>\n<li><strong>缓解模型幻觉</strong>：确保LLM的回答<strong>有据可依（Grounded）</strong>，答案来源于我们提供的知识，而不是模型自身的凭空捏造。</li>\n<li><strong>知识动态更新</strong>：当知识发生变化时，我们只需更新外部知识库，而无需重新训练昂贵的LLM。</li>\n<li><strong>处理私有数据</strong>：能够让LLM安全地利用企业内部的私有数据，而无需将这些数据用于模型训练。</li>\n</ul>","readingTime":{"minutes":3.94,"words":1181},"title":"RAG建设","type":"article"} }],
  ["/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/", { loader: () => import(/* webpackChunkName: "AIGC应用层建设思路_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC应用层建设思路/index.html.js"), meta: {"excerpt":"\n<p>AIGC应用层建设思路随笔</p>\n","readingTime":{"minutes":0.06,"words":18},"title":"AIGC应用层建设思路","type":"article"} }],
  ["/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/prompt%E5%B7%A5%E7%A8%8B.html", { loader: () => import(/* webpackChunkName: "AIGC应用层建设思路_prompt工程.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC应用层建设思路/prompt工程.html.js"), meta: {"excerpt":"<p><strong>1. 核心定位与原则</strong></p>\n<p>Prompt工程是人机（或应用程序与大语言模型）交互的桥梁，是所有AIGC应用与LLM沟通的核心。应用层的所有技术栈，如RAG和微调，其最终目标都是为了在合适的时机，生成一个信息最丰富、指令最明确的Prompt，并将其提交给LLM。</p>\n<p><strong>2. 优秀Prompt的构成要素</strong></p>\n<p>一个设计精良的Prompt通常是结构化的，并且包含以下部分：</p>\n<ul>\n<li><strong>角色 (Role)</strong>：定义模型的身份。\n<ul>\n<li><em>示例</em>：“你是一名专业的市场营销文案专家。”</li>\n</ul>\n</li>\n<li><strong>指令 (Instruction)</strong>：明确、无歧义地描述需要模型完成的核心任务。\n<ul>\n<li><em>示例</em>：“请为下面这款产品撰写三条社交媒体宣传文案。”</li>\n</ul>\n</li>\n<li><strong>上下文 (Context)</strong>：提供完成任务所需的所有背景信息。这部分通常是<strong>动态注入</strong>的，主要来源是：\n<ul>\n<li><strong>RAG库检索内容</strong>：从向量数据库（Milvus, Faiss等）中检索出的与用户问题最相关的知识片段。</li>\n<li><strong>用户会话历史</strong>：为了实现多轮对话的连贯性。</li>\n<li><strong>外部数据</strong>：通过API调用等方式获取的实时信息。</li>\n</ul>\n</li>\n<li><strong>示例 (Examples / Few-Shot)</strong>：提供一或多个输入输出的范例，帮助模型理解期望的风格和格式。\n<ul>\n<li><em>示例</em>：“例如，如果产品是咖啡豆，文案可以是：‘清晨的第一缕阳光，从一杯手冲开始。’现在，请为以下产品生成文案...”</li>\n</ul>\n</li>\n<li><strong>输出格式 (Output Format)</strong>：明确指定返回内容的格式。\n<ul>\n<li><em>示例</em>：“请将三条文案以JSON数组的格式返回，每个对象的键为‘copywriting’。”</li>\n</ul>\n</li>\n</ul>","readingTime":{"minutes":2.92,"words":876},"title":"prompt工程","type":"article"} }],
  ["/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6-agent.html", { loader: () => import(/* webpackChunkName: "AIGC应用层建设思路_业务流程控制-agent.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC应用层建设思路/业务流程控制-agent.html.js"), meta: {"excerpt":"<p><strong>1. 核心思想：从语言生成到任务执行</strong></p>\n<p>传统的LLM应用以“问-答”为主，而Agent化的应用则将LLM从一个“语言模型”升级为了一个“任务执行大脑”。其核心思想是：利用LLM强大的自然语言理解和推理能力，将其作为中心控制器，通过生成结构化的指令来调用外部工具（API、数据库、代码等），从而完成复杂的、多步骤的业务流程。</p>\n<p><strong>2. 单个Agent的内部构造 (The Anatomy of an Agent)</strong></p>\n<p>一个功能完备的Agent，是“思考”与“行动”的结合体，其内部通常包含三大核心组件：</p>","readingTime":{"minutes":3.7,"words":1109},"title":"业务流程控制-agent","type":"article"} }],
  ["/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/%E5%A4%9Aagent%E7%BB%84%E5%90%88.html", { loader: () => import(/* webpackChunkName: "AIGC应用层建设思路_多agent组合.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC应用层建设思路/多agent组合.html.js"), meta: {"excerpt":"<h4><strong>1. 从单一到协作：为什么需要多Agent？</strong></h4>\n<p>当任务的复杂度超出单个LLM（即使配备了工具和知识库）所能高效处理的范畴时，多Agent系统就应运而生。单一Agent模型如同一个全能的“通才”，但在面对需要深度专业知识、多重角色协作或复杂流程的场景时，会显得力不从心。多Agent系统，则像组建一个各有所长的“专家团队”。</p>\n<p>其核心优势在于：</p>\n<ul>\n<li><strong>任务分解与分治 (Task Decomposition &amp; Divide-and-Conquer)</strong>：将一个宏大、复杂的问题，拆解成多个更小、更易于管理和执行的子任务。每个子任务交由最擅长它的Agent来处理，最终将结果汇总，实现“分而治之”。</li>\n<li><strong>领域专长与深度 (Domain Expertise &amp; Depth)</strong>：允许我们创建多个“专家Agent”，例如“数据分析Agent”、“代码生成Agent”、“市场研究Agent”、“文案创作Agent”。每个Agent都可以拥有自己专属的Prompt、工具和知识库（RAG），从而在各自的垂直领域达到更高的专业水准和输出质量。</li>\n<li><strong>模块化与可扩展性 (Modularity &amp; Scalability)</strong>：系统由多个独立的Agent模块组成，使得开发、测试、维护和升级都变得更加容易。当需要增加新功能时，我们只需开发一个新的Agent并将其集成到系统中，而无需修改庞大而复杂的单体Agent。</li>\n<li><strong>并行处理与效率 (Parallelism &amp; Efficiency)</strong>：对于可以并行处理的子任务，可以调度多个Agent同时工作，从而缩短整个任务的完成时间。</li>\n</ul>","readingTime":{"minutes":5.68,"words":1703},"title":"多agent组合","type":"article"} }],
  ["/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/%E5%AE%89%E5%85%A8%E3%80%81%E9%9A%90%E7%A7%81%E4%B8%8E%E4%BC%A6%E7%90%86.html", { loader: () => import(/* webpackChunkName: "AIGC应用层建设思路_安全、隐私与伦理.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC应用层建设思路/安全、隐私与伦理.html.js"), meta: {"excerpt":"<p><strong>1. 核心理念：纵深防御（Defense-in-Depth）</strong></p>\n<p>构建一个安全、可靠且符合伦理的AIGC应用，需要建立一个多层次的防御体系。每一层都负责处理不同类型的风险，任何一层被绕过，后续的层次依然能提供保护。其防御流程贯穿数据处理的全链路：<code>用户输入 -&gt; 输入审查 -&gt; Prompt构建 -&gt; LLM推理 -&gt; 输出审查 -&gt; 返回用户</code>。</p>\n<p><strong>2. 安全性（Security）：防范恶意攻击</strong></p>\n<p>核心目标是防止用户通过恶意输入来操纵、滥用或破坏系统的正常功能。</p>","readingTime":{"minutes":3.53,"words":1060},"title":"安全、隐私与伦理","type":"article"} }],
  ["/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/%E5%BE%AE%E8%B0%83%E7%AD%96%E7%95%A5.html", { loader: () => import(/* webpackChunkName: "AIGC应用层建设思路_微调策略.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC应用层建设思路/微调策略.html.js"), meta: {"excerpt":"<h4><strong>1. 微调的目标与定位</strong></h4>\n<p>在上一篇文章中，我分享了对微调的理解。微调是在预训练模型的基础上，针对垂直领域进行特定任务的训练，或者可以理解为使用自身数据来进一步优化模型，使其更好地适应特定业务场景。这个过程的核心在于通过调整一系列关键参数和策略，来引导模型学习新的知识和行为范式。</p>\n<h4><strong>2. 微调策略的核心支柱</strong></h4>\n<p>一个成功的微调任务，可以从三个核心支柱来进行顶层设计：</p>\n<ul>\n<li><strong>A. 数据策略</strong>：定义了模型“学什么”。这包括如何准备、清洗和组织训练数据，以及如何设定输入输出的长度限制等。</li>\n<li><strong>B. 优化策略</strong>：定义了模型“怎么学”。这涉及到学习率、批次大小、优化器等超参数的选择，它们共同决定了模型参数更新的数学过程。</li>\n<li><strong>C. 训练策略</strong>：定义了“如何保障学习过程顺利进行”。这涉及到训练的步数/轮次、模型的保存与评估机制、以及使用何种分布式或加速技术（如DeepSpeed）等工程层面的配置。</li>\n</ul>","readingTime":{"minutes":6.48,"words":1943},"title":"微调策略","type":"article"} }],
  ["/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E8%BF%AD%E4%BB%A3.html", { loader: () => import(/* webpackChunkName: "AIGC应用层建设思路_模型评估与迭代.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC应用层建设思路/模型评估与迭代.html.js"), meta: {"excerpt":"<p><strong>1. 指导原则：场景、数据与模型的匹配</strong></p>\n<p>模型评估与迭代的第一步是基于业务的“顶层设计”。其核心原则是实现业务场景、可用数据和模型能力三者之间的最佳匹配。</p>\n<ul>\n<li><strong>场景决定模型架构</strong>：\n<ul>\n<li><strong>判别式任务</strong>（如意图识别、情感分类）：优先考虑轻量级的BERT、RoBERTa等编码器（Encoder）模型，或传统的机器学习模型（如XGBoost），成本效益高。</li>\n<li><strong>生成式任务</strong>（如多轮对话、文案撰写、代码生成）：需要选择基于Transformer架构的生成式大语言模型（LLM），如GPT系列、Llama系列，或支持MoE（混合专家）架构的模型以提高效率。</li>\n</ul>\n</li>\n<li><strong>数据决定策略与模型规模</strong>：\n<ul>\n<li><strong>数据量极少（&lt; 1万条）</strong>：<strong>不建议进行微调</strong>。微调很可能导致模型“过拟合”，忘记原有的通用能力。此时最佳策略是 <strong>RAG（检索增强生成）</strong>，将少量高质量数据作为上下文，通过Prompt工程来利用大模型的零样本（Zero-shot）或少样本（Few-shot）能力。</li>\n<li><strong>数据量中等（10万-100万条）</strong>：这是<strong>微调的最佳区间</strong>。可以选择一个合适尺寸的基础模型（如7B、13B，一般不超过30B）进行全量或部分参数微调（如LoRA）。目标是向模型注入领域知识和特定的任务范式。</li>\n<li><strong>数据量巨大（千万级以上）</strong>：具备了进行**持续预训练（Continual Pre-training）**甚至从零开始训练一个模型（Train from Scratch）的潜力。此时需要选择更大参数量的模型（如70B以上）来有效“吸收”海量数据中的知识。</li>\n</ul>\n</li>\n</ul>","readingTime":{"minutes":3.6,"words":1081},"title":"模型评估与迭代","type":"article"} }],
  ["/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5.html", { loader: () => import(/* webpackChunkName: "AIGC应用层建设思路_训练策略.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC应用层建设思路/训练策略.html.js"), meta: {"excerpt":"<h5><strong>1. 训练的目标：为何需要训练？</strong></h5>\n<p>在聊训练策略之前，先要阐述一个概念，为什么要做数据训练？</p>\n<p>通过海量数据让大语言模型（如GLM、GPT等）进行学习，使其能够理解和生成自然语言。这个过程类似于人类通过阅读大量的书籍和文章来学习语言。模型通过数据训练，逐渐掌握语法、语义、上下文理解等语言的各个方面，从而能够在面对新问题时生成有意义的回答或执行特定任务。</p>\n<p>用通俗易懂的说法可以理解为，<strong>人类整理的数据就是大模型的老师</strong>。它的一切知识都来源于训练的数据。</p>\n<h5><strong>2. 训练的基石：数据是第一要义</strong></h5>","readingTime":{"minutes":4.39,"words":1317},"title":"训练策略","type":"article"} }],
  ["/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%BF%90%E7%BB%B4.html", { loader: () => import(/* webpackChunkName: "AIGC应用层建设思路_部署与运维.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC应用层建设思路/部署与运维.html.js"), meta: {"excerpt":"<p><strong>1. 核心原则：将CI/CD扩展到模型和数据</strong></p>\n<p>LLMOps（大语言模型运维）的核心，是将传统DevOps中成熟的自动化、持续集成、持续部署（CI/CD）原则，扩展到包含**代码（Code）、模型（Model）和数据（Data）**三位一体的AI应用生命周期管理中。其目标是实现AI应用快速、可靠、可复现地交付与迭代。</p>\n<p><strong>2. LLMOps的生命周期闭环</strong></p>\n<p>一个完整的LLMOps流程是一个持续的循环：</p>\n<ol>\n<li><strong>数据管理与处理 (CI for Data)</strong>：自动化地收集、清洗、标注新的数据，并进行版本化管理。</li>\n<li><strong>模型训练与微调 (CT for Models)</strong>：当有新数据或新代码时，自动触发模型的微调或训练流程。</li>\n<li><strong>模型评估与验证 (CI for Models)</strong>：使用“黄金评估集”自动评估新生成的模型，只有当新模型的性能指标优于旧模型时，才允许进入部署环节。</li>\n<li><strong>模型打包与部署 (CD for Models)</strong>：将通过验证的模型、相关代码和配置打包成一个可部署的单元（如Docker镜像），并根据预设策略部署到生产环境。</li>\n<li><strong>线上服务与监控</strong>：模型上线后，对其性能、成本、效果和安全性进行全方位监控。</li>\n<li><strong>反馈收集</strong>：从线上监控和用户反馈中收集有价值的数据，并将其送回到第一步的数据管理环节，形成下一次迭代的基础。</li>\n</ol>","readingTime":{"minutes":3.38,"words":1015},"title":"部署与运维","type":"article"} }],
  ["/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/%E9%95%BF%E6%96%87%E6%9C%AC%E4%B8%8E%E7%AE%97%E5%8A%9B.html", { loader: () => import(/* webpackChunkName: "AIGC应用层建设思路_长文本与算力.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC应用层建设思路/长文本与算力.html.js"), meta: {"excerpt":"<h4><strong>1. 核心挑战：Transformer的二次方复杂度瓶颈</strong></h4>\n<p>要解决问题，首先要理解其根源。标准Transformer模型处理长文本时面临的核心挑战是其<strong>自注意力（Self-Attention）机制的二次方复杂度</strong>。</p>\n<ul>\n<li><strong>计算量</strong>：序列长度增加一倍，注意力计算量增加约四倍。</li>\n<li><strong>显存占用</strong>：存储注意力分数矩阵所需的显存同样以<code>O(n²)</code>级别增长。</li>\n</ul>\n<p>这意味着当文本长度从1k增加到32k时，对算力和显存的需求会增长约1000倍。因此，所有的优化策略，都是在想办法绕过或缓解这个瓶颈。</p>","readingTime":{"minutes":4.93,"words":1479},"title":"长文本与算力","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/RAG%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/", { loader: () => import(/* webpackChunkName: "AIGC框架详解_RAG核心组件_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/RAG核心组件/index.html.js"), meta: {"excerpt":"\n<p>RAG核心组件随笔</p>\n","readingTime":{"minutes":0.04,"words":12},"title":"RAG核心组件","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/Agent%E6%A1%86%E6%9E%B6/AutoGen.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_Agent框架_AutoGen.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/Agent框架/AutoGen.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：可定制的多Agent对话（Conversation）框架</strong></h4>\n<p>AutoGen是一个开源框架，旨在简化和赋能基于多Agent对话的下一代LLM应用。它的核心是提供一套强大的机制，来定义不同角色的Agent，并精心编排它们之间的“对话流程”，让它们通过“聊天”来协同解决问题。</p>\n<h4><strong>2. AutoGen的核心组件</strong></h4>\n<p>理解AutoGen的关键，在于理解其最基础的两个Agent类型：</p>\n<p><strong>A. <strong><code>**AssistantAgent**</code></strong> (助理Agent)</strong></p>","readingTime":{"minutes":4.6,"words":1380},"title":"AutoGen","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/Agent%E6%A1%86%E6%9E%B6/CrewAI.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_Agent框架_CrewAI.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/Agent框架/CrewAI.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：基于角色扮演的“流程自动化”框架</strong></h4>\n<p>CrewAI是一个开源框架，旨在帮助开发者轻松地编排、组织和运行多个自主Agent，让它们协同完成复杂的任务。</p>\n<p>它的核心理念是**“角色扮演（Role-Playing）”<strong>和</strong>“任务驱动（Task-Driven）”**。开发者不再需要去思考Agent之间底层的通信细节，而是像一个项目经理一样，去定义团队里需要哪些“角色”，每个角色需要完成哪些“任务”，以及整个团队的“工作流程”。</p>\n<h4><strong>2. CrewAI的四大核心组件</strong></h4>","readingTime":{"minutes":5.2,"words":1560},"title":"CrewAI","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/Agent%E6%A1%86%E6%9E%B6/", { loader: () => import(/* webpackChunkName: "AIGC框架详解_Agent框架_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/Agent框架/index.html.js"), meta: {"excerpt":"\n<p>Agent框架随笔</p>\n","readingTime":{"minutes":0.03,"words":8},"title":"Agent框架","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6/", { loader: () => import(/* webpackChunkName: "AIGC框架详解_基础框架_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/基础框架/index.html.js"), meta: {"excerpt":"\n","readingTime":{"minutes":0.01,"words":4},"title":"基础框架","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E4%B8%8E%E5%B7%A5%E5%85%B7/DeepSpeed.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_微调训练框架与工具_DeepSpeed.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/微调训练框架与工具/DeepSpeed.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：大规模AI模型的“超级增压器”</strong></h4>\n<p>如果说PyTorch是制造发动机的工具箱，那么DeepSpeed就是一套为这款发动机设计的、集成了<strong>涡轮增压、氮气加速、先进冷却系统于一体的“极限性能改装套件”</strong>。</p>\n<p>它的核心价值在于，让您能够在现有的硬件上，训练和推理更大规模的模型，或者以更高的效率来训练和推理同等规模的模型。它通过在并行计算、内存优化和推理加速等多个维度提供极致的优化来实现这一目标。</p>\n<h4><strong>2. 训练优化：ZeRO——DeepSpeed的“黑科技”</strong></h4>","readingTime":{"minutes":4.63,"words":1389},"title":"DeepSeed","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E4%B8%8E%E5%B7%A5%E5%85%B7/Hugging%20Face%20Trainer%20_%20PEFT.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_微调训练框架与工具_Hugging Face Trainer _ PEFT.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/微调训练框架与工具/Hugging Face Trainer _ PEFT.html.js"), meta: {"excerpt":"<h4><strong>1. Hugging Face <strong><code>**Trainer**</code></strong>：训练流程的“高级自动化”</strong></h4>\n<p><code>Trainer</code> 是 Hugging Face <code>transformers</code> 库中提供的一个高度封装、功能强大的训练工具类。它的核心目标，就是<strong>将开发者从手动编写PyTorch训练循环的繁琐工作中解放出来</strong>。</p>\n<p><strong>A. 核心组件</strong></p>\n<p>使用<code>Trainer</code>主要涉及两个核心类：</p>","readingTime":{"minutes":3.94,"words":1183},"title":"Hugging Face Trainer _ PEFT","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E4%B8%8E%E5%B7%A5%E5%85%B7/Llama-Alpaca-Factory.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_微调训练框架与工具_Llama-Alpaca-Factory.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/微调训练框架与工具/Llama-Alpaca-Factory.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：一站式、可视化的LLM微调平台</strong></h4>\n<p>Llama-Factory（现已更名为 Llama-Alpaca-Factory，但通常仍被简称为Llama-Factory）是一个开源项目，其核心目标是<strong>将复杂、代码驱动的LLM微调流程，简化为一个人人都能轻松上手的、可视化的、一键式的操作体验</strong>。</p>\n<p>它本身并不是一个底层的深度学习框架，而是一个构建在 <strong>Hugging Face <strong><code>**Trainer**</code>、<code>**PEFT**</code>、<code>**transformers**</code> 和 <code>**DeepSpeed**</code> 等一系列强大工具之上的、高度集成的</strong>“上层应用”</strong>。</p>","readingTime":{"minutes":3.8,"words":1139},"title":"Llama-Alpaca-Factory","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E4%B8%8E%E5%B7%A5%E5%85%B7/", { loader: () => import(/* webpackChunkName: "AIGC框架详解_微调训练框架与工具_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/微调训练框架与工具/index.html.js"), meta: {"excerpt":"\n<p>微调训练框架与工具随笔</p>\n","readingTime":{"minutes":0.07,"words":20},"title":"微调训练框架与工具","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/RAG%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B8%8E%E5%88%87%E5%88%86/", { loader: () => import(/* webpackChunkName: "AIGC框架详解_RAG核心组件_数据处理与切分_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/RAG核心组件/数据处理与切分/index.html.js"), meta: {"excerpt":"\n<p>数据处理与切分随笔</p>\n","readingTime":{"minutes":0.05,"words":16},"title":"数据处理与切分","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/RAG%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B8%8E%E5%88%87%E5%88%86/%E6%96%87%E6%9C%AC%E5%88%86%E5%89%B2%E5%99%A8-Text%20Splitters.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_RAG核心组件_数据处理与切分_文本分割器-Text Splitters.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/RAG核心组件/数据处理与切分/文本分割器-Text Splitters.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：RAG流程的“智能备菜工”</strong></h4>\n<p>Text Splitters（文本分割器）是在构建RAG系统时，负责将加载进来的长文档（<code>Documents</code>）切分成多个更小的、独立的、但又在语义上相关的文本块（<code>Chunks</code>）的工具。这是进行Embedding和向量化之前的<strong>强制性预处理步骤</strong>。</p>\n<h4><strong>2. 为什么必须进行文本分割？</strong></h4>\n<p>直接将一整篇长文档进行Embedding是不可行且无效的，主要有两个原因：</p>","readingTime":{"minutes":4.58,"words":1374},"title":"文本分割器","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/RAG%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B8%8E%E5%88%87%E5%88%86/%E6%96%87%E6%A1%A3%E5%8A%A0%E8%BD%BD%E5%99%A8-Document%20Loaders.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_RAG核心组件_数据处理与切分_文档加载器-Document Loaders.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/RAG核心组件/数据处理与切分/文档加载器-Document Loaders.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：连接数据源的“万能插头”</strong></h4>\n<p>Document Loaders (文档加载器) 是RAG流程的<strong>起点</strong>。它的核心职责是读取来自各种不同来源和格式的数据，并将其转换成一个标准化的、LangChain或LlamaIndex能够理解的 <code>Document</code> 对象。</p>\n<p>一个 <code>Document</code> 对象通常包含两部分内容：</p>\n<ul>\n<li><code>**page_content**</code>: 文档的主要文本内容。</li>\n<li><code>**metadata**</code>: 描述文档的元数据，例如来源文件名、页码、网址、作者等。</li>\n</ul>","readingTime":{"minutes":3.44,"words":1033},"title":"文档加载器","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/RAG%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/Embedding%E6%A8%A1%E5%9E%8B/BGE%E6%A8%A1%E5%9E%8B.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_RAG核心组件_Embedding模型_BGE模型.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/RAG核心组件/Embedding模型/BGE模型.html.js"), meta: {"excerpt":"<h4><strong>1. BGE Embedding模型：语义检索的“全能冠军”</strong></h4>\n<p>BGE (BAAI General Embedding) 的核心定位是成为一个<strong>通用、高性能</strong>的文本嵌入模型系列。它经过了从<code>v1.5</code>版本到最新的<code>M3</code>版本的持续迭代，能力不断增强。</p>\n<h5><strong>旗舰模型：BGE-M3</strong></h5>\n<p>BGE-M3是该系列的最新力作，它不仅仅是一个Embedding模型，更是一个**“多功能一体化”的检索基础模型**。</p>\n","readingTime":{"minutes":4.77,"words":1432},"title":"BGE模型","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/RAG%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/Embedding%E6%A8%A1%E5%9E%8B/M3E%E6%A8%A1%E5%9E%8B.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_RAG核心组件_Embedding模型_M3E模型.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/RAG核心组件/Embedding模型/M3E模型.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：为中英双语优化的“All-in-One”语义向量模型</strong></h4>\n<p>M3E（Moka Massive Mixed Embedding）系列模型的核心定位是成为一个<strong>高效、全能的中英双语文本嵌入模型</strong>。它的设计目标是“All-in-One”，即用一个模型来出色地完成多种常见的检索任务，如文本相似度计算、语义检索等。</p>\n<p>它的训练语料库非常庞大，包含了超过2.2亿的中文句对和1.45亿的英文三元组，这为其强大的中英文语义理解能力奠定了坚实的基础。</p>\n<h4><strong>2. M3E的核心特性</strong></h4>","readingTime":{"minutes":3.47,"words":1041},"title":"M3E模型","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/RAG%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/Embedding%E6%A8%A1%E5%9E%8B/", { loader: () => import(/* webpackChunkName: "AIGC框架详解_RAG核心组件_Embedding模型_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/RAG核心组件/Embedding模型/index.html.js"), meta: {"excerpt":"\n<p>Embedding模型随笔</p>\n","readingTime":{"minutes":0.03,"words":8},"title":"Embedding模型","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/RAG%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/Embedding%E6%A8%A1%E5%9E%8B/text-embedding-ada-002%E6%A8%A1%E5%9E%8B.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_RAG核心组件_Embedding模型_text-embedding-ada-002模型.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/RAG核心组件/Embedding模型/text-embedding-ada-002模型.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：文本的“语义坐标转换器”</strong></h4>\n<p>如果说向量数据库是一个高维度的“宇宙空间”，那么Embedding模型就是这个宇宙的**“通用物理定律”<strong>或者</strong>“GPS定位系统”**。</p>\n<p>它的核心任务只有一个：<strong>将人类能够理解的、非结构化的文本（Text），转换成计算机能够理解和计算的、结构化的数字坐标——向量（Vector）。</strong></p>\n<p>这个“坐标”并非随机生成，它精确地捕捉了文本的<strong>语义（Semantic Meaning）</strong>。在由这个模型所定义的“语义宇宙”中，意思相近的文本，它们的坐标点在空间中的距离也就越近。</p>","readingTime":{"minutes":4.23,"words":1270},"title":"text-embedding-ada-002模型","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/RAG%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/ChromaDB%20_%20Weaviate.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_RAG核心组件_向量数据库_ChromaDB _ Weaviate.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/RAG核心组件/向量数据库/ChromaDB _ Weaviate.html.js"), meta: {"excerpt":"<p><strong>1. 核心定位：为开发者设计的、开源的嵌入式向量数据库</strong></p>\n<p>ChromaDB（通常简称Chroma）的设计哲学是<strong>简单、易用、开箱即用</strong>。它极大地降低了开发者使用向量数据库的门槛，非常适合快速原型设计、中小型项目以及作为应用的内置（embedded）向量存储引擎。</p>\n<p><strong>2. 核心特性</strong></p>\n<ul>\n<li><strong>API优先</strong>：提供了简洁、直观的Python和JavaScript/TypeScript客户端。</li>\n<li><strong>嵌入式与客户端-服务器模式</strong>：\n<ul>\n<li><strong>嵌入式 (In-Memory)</strong>：无需安装任何独立的数据库服务，可以直接在您的Python代码中运行，数据默认存储在内存或本地磁盘，非常适合本地开发和测试。</li>\n<li><strong>客户端-服务器</strong>：也可以作为独立的服务器运行，让多个应用通过网络连接和访问。</li>\n</ul>\n</li>\n<li><strong>元数据与过滤</strong>：这是它相比Faiss的一大优势。在存储向量的同时，可以存入丰富的元数据（如文档来源、作者、日期等），并在查询时根据这些元数据进行<strong>前置或后置过滤</strong>，实现更精确的检索。</li>\n<li><strong>与生态的集成</strong>：与LangChain、LlamaIndex等框架深度集成，可以无缝替换。</li>\n</ul>","readingTime":{"minutes":4.65,"words":1394},"title":"ChromaDB _ Weaviate","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/RAG%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/", { loader: () => import(/* webpackChunkName: "AIGC框架详解_RAG核心组件_向量数据库_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/RAG核心组件/向量数据库/index.html.js"), meta: {"excerpt":"\n<p>向量数据库随笔</p>\n","readingTime":{"minutes":0.04,"words":12},"title":"向量数据库","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/RAG%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/faiss%E5%BA%93.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_RAG核心组件_向量数据库_faiss库.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/RAG核心组件/向量数据库/faiss库.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：向量检索的“高性能计算引擎”</strong></h4>\n<p>Faiss (Facebook AI Similarity Search) 是由 <strong>Facebook AI Research（现Meta AI）开发的、一个专注于高性能向量相似度搜索</strong>的<strong>开源库（Library）</strong>。</p>\n<p>最核心的认知是：<strong>Faiss不是一个数据库，而是一个算法库。</strong></p>\n<p>我们可以用一个比喻来理解它和向量数据库的关系：</p>\n<ul>\n<li><strong>Faiss</strong>：如同汽车里那台经过极致性能优化的**“V12发动机”**。它的唯一职责就是以最快的速度进行核心计算（向量相似度搜索），它本身不带轮子、方向盘或车身。</li>\n<li><strong>ChromaDB / Milvus</strong>：则是一辆**“完整的汽车”**。这辆汽车的心脏可能就是一台类似Faiss的发动机，但它还提供了方向盘（API接口）、车身（数据管理）、油箱（持久化存储）、轮胎（网络服务）等所有部件，让可以直接“驾驶”。</li>\n</ul>","readingTime":{"minutes":5.07,"words":1521},"title":"faiss库","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/RAG%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/milvus.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_RAG核心组件_向量数据库_milvus.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/RAG核心组件/向量数据库/milvus.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：为AI应用打造的云原生“分布式向量数据库”</strong></h4>\n<p>Milvus是一个<strong>开源的、专为向量检索设计的云原生数据库</strong>。它的核心定位，可以类比为传统数据领域的 <strong>MySQL</strong> 或 <strong>PostgreSQL</strong>——一个功能全面、性能卓越、稳定可靠、为生产环境而生的基础设施。</p>\n<p>它从一开始就不是为单机或小型项目设计的，其整个架构都围绕着**可扩展性（Scalability）、可靠性（Reliability）和高性能（High Performance）**这三个企业级核心需求来构建。</p>","readingTime":{"minutes":4.67,"words":1401},"title":"milvus","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6/%E5%BA%94%E7%94%A8%E7%BC%96%E6%8E%92%E6%A1%86%E6%9E%B6/LangChain.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_基础框架_应用编排框架_LangChain.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/基础框架/应用编排框架/LangChain.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：AIGC应用开发的“Spring Boot”</strong></h4>\n<p>如果说PyTorch是让我们能“造出”高性能发动机（LLM）的底层工具集，那么LangChain就是一套能让我们快速“组装”出一辆功能完备的汽车（AIGC应用）的<strong>应用层开发框架</strong>。</p>\n<p>它通过提供一系列标准化的、可组合的组件，极大地简化了构建复杂AIGC应用（如RAG、Agents）的过程，其核心哲学与Spring Boot如出一辙：<strong>约定优于配置、快速开发、功能集成</strong>。</p>\n<h4><strong>2. LangChain的核心封装模块</strong></h4>","readingTime":{"minutes":4.11,"words":1232},"title":"LangChain","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6/%E5%BA%94%E7%94%A8%E7%BC%96%E6%8E%92%E6%A1%86%E6%9E%B6/LlamaIndex.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_基础框架_应用编排框架_LlamaIndex.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/基础框架/应用编排框架/LlamaIndex.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：为LLM应用打造的专属“数据框架”</strong></h4>\n<p>LlamaIndex的诞生，源于一个核心洞察：当LLM应用与外部数据结合时，最大的挑战往往来自于如何高效地<strong>摄取、索引、检索和合成</strong>这些数据。LangChain虽然也提供RAG功能，但LlamaIndex在此领域做得更深入、更专业。</p>\n<p>它的设计哲学是**“以数据为中心（Data-Centric）”**，旨在提供最强大、最灵活的工具，来连接私有或领域特定数据与大语言模型。</p>\n<h4><strong>2. LlamaIndex解决了哪些核心痛点？</strong></h4>","readingTime":{"minutes":4.76,"words":1429},"title":"LlamaIndex","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6/%E5%BA%94%E7%94%A8%E7%BC%96%E6%8E%92%E6%A1%86%E6%9E%B6/", { loader: () => import(/* webpackChunkName: "AIGC框架详解_基础框架_应用编排框架_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/基础框架/应用编排框架/index.html.js"), meta: {"excerpt":"\n<p>应用编排框架随笔</p>\n","readingTime":{"minutes":0.05,"words":14},"title":"应用编排框架","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6/%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%AE%97%E6%B3%95%E5%BA%93/Hugging%20Face%20Transformers.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_基础框架_模型与算法库_Hugging Face Transformers.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/基础框架/模型与算法库/Hugging Face Transformers.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：AI模型的“GitHub”与“Maven”</strong></h4>\n<p>Hugging Face 不仅仅是一个名为 <code>transformers</code> 的Python库，它是一个庞大的生态系统。其核心可以被理解为<strong>AI领域的“GitHub”与“Maven”的结合体</strong>：</p>\n<ul>\n<li><strong>作为“GitHub”</strong>：它提供了一个名为 <strong>Hugging Face Hub</strong> 的中央仓库，全世界的研究者和开发者都可以在这里上传、分享、发现和下载数以十万计的预训练模型、数据集和演示应用（Spaces）。</li>\n<li><strong>作为“Maven”</strong>：它旗下的 <code>transformers</code> 库，提供了一套标准化的接口，让您可以极其方便地在您的代码中，从Hub上下载并使用这些模型，解决了AI领域的“依赖管理”问题。</li>\n</ul>","readingTime":{"minutes":3.64,"words":1093},"title":"Hugging Face Transformers","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6/%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%AE%97%E6%B3%95%E5%BA%93/", { loader: () => import(/* webpackChunkName: "AIGC框架详解_基础框架_模型与算法库_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/基础框架/模型与算法库/index.html.js"), meta: {"excerpt":"\n<p>模型与算法库随笔</p>\n","readingTime":{"minutes":0.05,"words":14},"title":"模型与算法库","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/Pytorch.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_基础框架_深度学习框架_Pytorch.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/基础框架/深度学习框架/Pytorch.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位：一个以Python为先、灵活强大的深度学习框架</strong></h4>\n<p>PyTorch是构建所有现代AI模型（包括Transformer）的底层基础。它并非一个开箱即用的“应用”，而是一个“工具箱”或“开发平台”。开发者可以用它来定义、训练和部署任意复杂的神经网络。</p>\n<ul>\n<li><strong>与Spring的类比</strong>：Spring为Java应用提供了Bean管理、依赖注入、AOP等底层能力，但不会规定您的业务逻辑必须如何实现。同样，PyTorch提供了张量（Tensors）、自动求导、神经网络层等核心部件，让开发者可以自由地构建任何能想象到的模型结构，<strong>控制力极强</strong>。</li>\n<li><strong>Pythonic（贴近Python风格）</strong>：PyTorch的设计哲学与Python的风格深度融合，其代码直观、易于上手，调试过程也像在写普通的Python程序一样简单，这是它广受学术界和研究人员喜爱的重要原因。</li>\n</ul>","readingTime":{"minutes":6.36,"words":1907},"title":"Pytorch","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/", { loader: () => import(/* webpackChunkName: "AIGC框架详解_基础框架_深度学习框架_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/基础框架/深度学习框架/index.html.js"), meta: {"excerpt":"\n<p>深度学习框架随笔</p>\n","readingTime":{"minutes":0.05,"words":14},"title":"深度学习框架","type":"article"} }],
  ["/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/TensorFlow_Keras.html", { loader: () => import(/* webpackChunkName: "AIGC框架详解_基础框架_深度学习框架_TensorFlow_Keras.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/AIGC框架详解/基础框架/深度学习框架/TensorFlow_Keras.html.js"), meta: {"excerpt":"<h4><strong>1. 核心定位与关系：强大的引擎与优雅的接口</strong></h4>\n<p>TensorFlow 是由 Google 开发的、一个用于高性能数值计算的开源平台。它的设计初衷就是为了应对大规模的、分布式的训练和部署场景，在工业界有着极其深厚的基础。</p>\n<p>Keras 则是一个高级神经网络API，它以**“以人为本”**为设计原则，旨在实现快速、简单的原型设计。它的接口清晰、模块化，极大地降低了深度学习的入门门槛。</p>\n<p><strong>现代关系</strong>：从TensorFlow 2.x开始，Keras 已被完全整合并作为其官方唯一推荐的高级API，我们通过 <code>tensorflow.keras</code>（通常简写为<code>tf.keras</code>）来使用它。可以这样理解：<strong>我们使用Keras简洁的语法来定义模型，而底层的计算、优化和部署则由强大的TensorFlow引擎来执行。</strong></p>","readingTime":{"minutes":5.32,"words":1595},"title":"TensorFlow_Keras","type":"article"} }],
  ["/404.html", { loader: () => import(/* webpackChunkName: "404.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/404.html.js"), meta: {"title":""} }],
  ["/category/", { loader: () => import(/* webpackChunkName: "category_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/category/index.html.js"), meta: {"title":"分类","index":false} }],
  ["/tag/", { loader: () => import(/* webpackChunkName: "tag_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/tag/index.html.js"), meta: {"title":"标签","index":false} }],
  ["/article/", { loader: () => import(/* webpackChunkName: "article_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/article/index.html.js"), meta: {"title":"文章","index":false} }],
  ["/star/", { loader: () => import(/* webpackChunkName: "star_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/star/index.html.js"), meta: {"title":"星标","index":false} }],
  ["/timeline/", { loader: () => import(/* webpackChunkName: "timeline_index.html" */"/Users/zhutingxuan/IdeaProjects/knowledge-base/docs/.vuepress/.temp/pages/timeline/index.html.js"), meta: {"title":"时间轴","index":false} }],
]);

if (import.meta.webpackHot) {
  import.meta.webpackHot.accept()
  if (__VUE_HMR_RUNTIME__.updateRoutes) {
    __VUE_HMR_RUNTIME__.updateRoutes(routes)
  }
  if (__VUE_HMR_RUNTIME__.updateRedirects) {
    __VUE_HMR_RUNTIME__.updateRedirects(redirects)
  }
}

if (import.meta.hot) {
  import.meta.hot.accept(({ routes, redirects }) => {
    __VUE_HMR_RUNTIME__.updateRoutes(routes)
    __VUE_HMR_RUNTIME__.updateRedirects(redirects)
  })
}

<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.94" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <title>Pytorch | 我的知识库</title><meta name="description" content="一个记录学习与思考的地方">
    <link rel="preload" href="/knowledge-base/assets/style-Dmo5Xz_6.css" as="style"><link rel="stylesheet" href="/knowledge-base/assets/style-Dmo5Xz_6.css">
    <link rel="modulepreload" href="/knowledge-base/assets/app-Cr2W10WY.js"><link rel="modulepreload" href="/knowledge-base/assets/Pytorch.html-BAbgOdb5.js"><link rel="modulepreload" href="/knowledge-base/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/knowledge-base/assets/index.html-BO_sSkOq.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-o1svxq4-.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-BL44StxI.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/knowledge-management.html-CKivu2EZ.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/retrospective.html-C5xJ63iJ.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/estimation.html-BETINU_W.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/risk-management.html-D-_Xxmw_.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/stakeholder-analysis.html-Dgyddr8t.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/wbs.html-ChZI5GF5.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/change-management.html-BImvpnSp.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/meeting-management.html-BH58vt_-.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/scrum.html-FsvvA5_8.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/tracking.html-DwOeMQkc.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/dora-metrics.html-DFsXkePL.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/leadership.html-DLez_VE_.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/okr.html-COiTipPE.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/pm-pdm-collaboration.html-BBwuPNS7.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/AIGC应用层建设思路.html-Bg7tmGLX.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/RAG建设.html-DpY8YQvi.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-BexeRTcy.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/prompt工程.html-DyazWmY9.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/业务流程控制-agent.html-DLCtP8-k.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/多agent组合.html-EfKja25o.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/安全、隐私与伦理.html-B0qpoWLt.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/微调策略.html-mxvwqTOe.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/模型评估与迭代.html-BwQ75ELG.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/训练策略.html-gD5MYPzy.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/部署与运维.html-BNZFpa3A.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/长文本与算力.html-B7MrIuOQ.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-Dsqp-mT5.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-jSKO9YKm.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/TGI.html-BR3UKoto.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/vLLM.html-CfIweWn7.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-x9-aU7zr.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/pt_ft.html-DDJwweyX.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/rag.html-CahVfa3T.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/rlhf_dpo.html-DT6Y8q-t.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/AutoGen.html-Csq6LeCH.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/CrewAI.html-C8_kEjxb.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-B9rEt_Zq.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-Dcm-3jDe.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-DyxqdbK4.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/DeepSpeed.html-zS0ZxRwl.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/Hugging Face Trainer _ PEFT.html-9JBWTZd7.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/Llama-Alpaca-Factory.html-ByY09koh.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-NL3QkGKa.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/LangChain.html-CMuvwGH7.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/LlamaIndex.html-Bou4zc7m.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-B5rILKN7.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-pcbpP5_F.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/TensorFlow_Keras.html-7FxkX3wO.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/Hugging Face Transformers.html-ByIyXFYg.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-Dowqqiu8.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/BGE模型.html-DHXqx4av.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/M3E模型.html-BSTAu44X.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-CmgJjZwv.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/text-embedding-ada-002模型.html-CP5EcL7z.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/ChromaDB _ Weaviate.html-B3qW7LF7.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-CXuvAiOa.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/faiss库.html-Co5jQxia.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/milvus.html-BD4I1Qqx.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-0dxFG2Qq.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/文本分割器-Text Splitters.html-Butic1gj.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/文档加载器-Document Loaders.html-Ckeg-pQJ.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/404.html-DYeD0y6u.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-CrY9Vbhr.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-BZMf8kuQ.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-DNSP4c0C.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-yCJVGmuA.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-BbSvUT7W.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-B1PoA8dR.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-DG6PQDQ_.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-DNHyc8aI.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-C-e6yg11.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/photoswipe.esm-CKV1Bsxh.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/knowledge-base/" aria-label="带我回家"><!----><!----><span class="vp-site-name">我的知识库</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/knowledge-base/" aria-label="首页"><!--[--><i class="vp-icon fas fa-home" sizing="height"></i><!--]-->首页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/knowledge-base/management/" aria-label="管理随笔"><!--[--><i class="vp-icon fas fa-people-roof" sizing="height"></i><!--]-->管理随笔<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/knowledge-base/tech/" aria-label="技术随笔"><!--[--><i class="vp-icon fas fa-code" sizing="height"></i><!--]-->技术随笔<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!----><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">AIGC应用层建设思路</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">AIGC框架详解</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">基础框架</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">深度学习框架</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/knowledge-base/tech/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/Pytorch.html" aria-label="Pytorch"><!--[--><i class="vp-icon fas fa-file-lines fa-fw" sizing="both"></i><!--]-->Pytorch<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/knowledge-base/tech/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/TensorFlow_Keras.html" aria-label="TensorFlow Keras"><!--[--><i class="vp-icon fas fa-file-lines fa-fw" sizing="both"></i><!--]-->TensorFlow Keras<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">应用编排框架</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">模型与算法库</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">微调训练框架与工具</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">RAG核心组件</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">Agent框架</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">推理服务与部署</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">数据结构汇总</span><span class="vp-arrow end"></span></button><!----></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Pytorch</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">codingXuan</span></span><span property="author" content="codingXuan"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2024/9/8</span><meta property="datePublished" content="2024-09-08T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 6 分钟</span><meta property="timeRequired" content="PT6M"></span><!----><!----></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><h4 id="_1-核心定位-一个以python为先、灵活强大的深度学习框架" tabindex="-1"><a class="header-anchor" href="#_1-核心定位-一个以python为先、灵活强大的深度学习框架"><span><strong>1. 核心定位：一个以Python为先、灵活强大的深度学习框架</strong></span></a></h4><p>PyTorch是构建所有现代AI模型（包括Transformer）的底层基础。它并非一个开箱即用的“应用”，而是一个“工具箱”或“开发平台”。开发者可以用它来定义、训练和部署任意复杂的神经网络。</p><ul><li><strong>与Spring的类比</strong>：Spring为Java应用提供了Bean管理、依赖注入、AOP等底层能力，但不会规定您的业务逻辑必须如何实现。同样，PyTorch提供了张量（Tensors）、自动求导、神经网络层等核心部件，让开发者可以自由地构建任何能想象到的模型结构，<strong>控制力极强</strong>。</li><li><strong>Pythonic（贴近Python风格）</strong>：PyTorch的设计哲学与Python的风格深度融合，其代码直观、易于上手，调试过程也像在写普通的Python程序一样简单，这是它广受学术界和研究人员喜爱的重要原因。</li></ul><h4 id="_2-pytorch的核心组件" tabindex="-1"><a class="header-anchor" href="#_2-pytorch的核心组件"><span><strong>2. PyTorch的核心组件</strong></span></a></h4><p>要理解PyTorch，需要掌握其最核心的几个概念：</p><p><strong>A. 张量 (torch.Tensor)</strong></p><ul><li><strong>定义</strong>：张量是PyTorch中最基本的数据结构，可以理解为一个多维数组。它与大家熟知的NumPy <code>ndarray</code> 非常相似，但有两个关键的超能力： <ol><li><strong>GPU加速</strong>：可以非常方便地将张量移动到GPU上进行计算，从而利用GPU强大的并行计算能力。</li><li><strong>自动求导</strong>：能够自动追踪其上的所有操作，以便后续进行梯度计算。</li></ol></li><li><strong>作用</strong>：无论是输入的数据、模型的权重，还是计算过程中的中间变量，在PyTorch中都以张量的形式存在。</li></ul><p><strong>B. 动态计算图 (Dynamic Computational Graph) 与 Autograd 引擎</strong></p><p>这是PyTorch的“魔法”所在，也是其与早期TensorFlow最大的区别。</p><ul><li><strong>动态图（Define-by-Run）</strong>：计算图（描述了数据如何流经各个计算节点）是在代码<strong>运行时</strong>被动态构建的。这意味着可以在代码中使用标准的Python控制流（如<code>for</code>循环、<code>if</code>语句），计算图会根据代码执行路径而改变。这使得模型构建和调试都非常直观和灵活。</li><li><strong>Autograd引擎</strong>：当在一个需要梯度的张量上执行操作时，PyTorch会自动构建这个计算图。在最终的损失（loss）上调用 <code>.backward()</code> 方法时，<code>autograd</code> 引擎会沿着这个图反向传播，自动计算出所有参与训练的参数（权重）的梯度。开发者完全不需要手动编写复杂的求导公式。</li></ul><p><strong>C. 神经网络模块 (</strong><code>**torch.nn**</code><strong>)</strong></p><p><code>torch.nn</code> 是PyTorch专门用于构建神经网络的核心模块。</p><ul><li><code>**nn.Module**</code>：所有神经网络模型或层都应该继承自这个基类。在自定义模型时，通常会在 <code>__init__</code> 方法中定义所需的层（如卷积层、线性层），在 <code>forward</code> 方法中定义数据从输入到输出的前向传播逻辑。</li><li><strong>预定义层</strong>：<code>torch.nn</code> 提供了所有标准化的神经网络层，如<code>nn.Linear</code>, <code>nn.Conv2d</code>, <code>nn.LSTM</code>, <code>nn.TransformerEncoderLayer</code>等，开发者可以像搭积木一样将它们组合起来。</li></ul><p><strong>D. 优化器 (</strong><code>**torch.optim**</code><strong>)</strong></p><p>这个模块包含了所有标准的优化算法，用于在计算出梯度后，根据梯度来更新模型的权重。</p><ul><li><strong>常用优化器</strong>：<code>optim.SGD</code> (随机梯度下降), <code>optim.Adam</code>, <code>optim.AdamW</code> (目前LLM训练中最常用的优化器) 等。</li></ul><h4 id="_3-代码示例-一个完整的pytorch训练流程" tabindex="-1"><a class="header-anchor" href="#_3-代码示例-一个完整的pytorch训练流程"><span><strong>3. 代码示例：一个完整的PyTorch训练流程</strong></span></a></h4><p>下面的代码将演示如何使用PyTorch的全部核心组件，来完成一个最基础的机器学习任务——线性回归（拟合函数 <code>y = 2x + 1</code>）。这个例子将把上面提到的所有抽象概念付诸实践。</p><div class="language-plain line-numbers-mode" data-highlighter="shiki" data-ext="plain" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-plain"><span class="line"><span>import torch</span></span>
<span class="line"><span>import torch.nn as nn</span></span>
<span class="line"><span></span></span>
<span class="line"><span># --- 1. 数据准备 (核心组件: Tensor) ---</span></span>
<span class="line"><span># 创建一些样本数据，X是输入，y是期望的输出</span></span>
<span class="line"><span># 我们希望模型能从这些数据中学到 y 约等于 2*X + 1 这个规律</span></span>
<span class="line"><span>X_numpy = torch.arange(0, 10, 0.1).view(-1, 1)</span></span>
<span class="line"><span>y_numpy = 2 * X_numpy + 1 + torch.randn(X_numpy.shape) * 0.5 # 加入一些随机噪声</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 将数据转换为PyTorch的Tensor</span></span>
<span class="line"><span>X = X_numpy.clone().detach().requires_grad_(False)</span></span>
<span class="line"><span>y = y_numpy.clone().detach().requires_grad_(False)</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span># --- 2. 模型构建 (核心组件: nn.Module) ---</span></span>
<span class="line"><span># 创建一个线性回归模型，它继承自 nn.Module</span></span>
<span class="line"><span>class LinearRegressionModel(nn.Module):</span></span>
<span class="line"><span>    def __init__(self):</span></span>
<span class="line"><span>        super(LinearRegressionModel, self).__init__()</span></span>
<span class="line"><span>        # 定义一个线性层。输入维度是1，输出维度也是1。</span></span>
<span class="line"><span>        self.linear = nn.Linear(1, 1)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    def forward(self, x):</span></span>
<span class="line"><span>        # 定义数据如何通过模型（前向传播）</span></span>
<span class="line"><span>        return self.linear(x)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 实例化模型</span></span>
<span class="line"><span>model = LinearRegressionModel()</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span># --- 3. 定义损失函数和优化器 (核心组件: nn, optim) ---</span></span>
<span class="line"><span># 使用均方误差作为损失函数</span></span>
<span class="line"><span>loss_fn = nn.MSELoss()</span></span>
<span class="line"><span># 使用随机梯度下降(SGD)作为优化器，告诉它要去更新 model 的所有参数 (model.parameters())</span></span>
<span class="line"><span># lr 是学习率 (learning rate)</span></span>
<span class="line"><span>optimizer = torch.optim.SGD(model.parameters(), lr=0.01)</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span># --- 4. 训练循环 (核心流程与Autograd的应用) ---</span></span>
<span class="line"><span>num_epochs = 100 # 训练100个周期</span></span>
<span class="line"><span></span></span>
<span class="line"><span>for epoch in range(num_epochs):</span></span>
<span class="line"><span>    # a. 前向传播：将数据输入模型，得到预测结果</span></span>
<span class="line"><span>    y_pred = model(X)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    # b. 计算损失：比较预测结果和真实结果的差距</span></span>
<span class="line"><span>    loss = loss_fn(y_pred, y)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    # c. 反向传播 (Autograd大显身手的地方)</span></span>
<span class="line"><span>    #    首先，清零上一轮的梯度</span></span>
<span class="line"><span>    optimizer.zero_grad()</span></span>
<span class="line"><span>    #    然后，自动计算当前损失下，所有参数的梯度</span></span>
<span class="line"><span>    loss.backward()</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    # d. 更新权重：优化器根据计算出的梯度，来更新模型的权重</span></span>
<span class="line"><span>    optimizer.step()</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    # 打印训练过程</span></span>
<span class="line"><span>    if (epoch + 1) % 10 == 0:</span></span>
<span class="line"><span>        print(f&#39;Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}&#39;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span># --- 5. 使用训练好的模型进行预测 ---</span></span>
<span class="line"><span>print(&quot;\n训练完成!&quot;)</span></span>
<span class="line"><span># 我们可以看到模型学到的权重和偏置</span></span>
<span class="line"><span># model.parameters()返回一个迭代器，我们可以遍历它</span></span>
<span class="line"><span># 第一个是权重(weight)，第二个是偏置(bias)</span></span>
<span class="line"><span>trained_weight = list(model.parameters())[0].item()</span></span>
<span class="line"><span>trained_bias = list(model.parameters())[1].item()</span></span>
<span class="line"><span>print(f&quot;模型学到的规律: y = {trained_weight:.4f}x + {trained_bias:.4f}&quot;)</span></span>
<span class="line"><span>print(&quot;真实规律是: y = 2.0000x + 1.0000&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 用一个新数据点进行预测</span></span>
<span class="line"><span>new_x = torch.tensor([[15.0]])</span></span>
<span class="line"><span>with torch.no_grad(): # 在推理时，我们不需要计算梯度</span></span>
<span class="line"><span>    predicted_y = model(new_x)</span></span>
<span class="line"><span>    print(f&quot;\n当 x = 15.0 时, 模型的预测值 y = {predicted_y.item():.4f}&quot;)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_4-使用pytorch的标准工作流" tabindex="-1"><a class="header-anchor" href="#_4-使用pytorch的标准工作流"><span><strong>4. 使用PyTorch的标准工作流</strong></span></a></h4><p>一个典型的模型训练流程如下：</p><ol><li><strong>数据准备</strong>：使用 <code>torch.utils.data.Dataset</code> 和 <code>DataLoader</code> 来加载、预处理和组织数据。</li><li><strong>模型构建</strong>：创建一个继承自 <code>nn.Module</code> 的类，定义网络结构。</li><li><strong>定义损失函数和优化器</strong>：从 <code>torch.nn</code> 和 <code>torch.optim</code> 中选择合适的损失函数（如<code>nn.CrossEntropyLoss</code>）和优化器。</li><li><strong>训练循环</strong>： <ul><li>遍历数据加载器（DataLoader）。</li><li>将数据送入模型进行前向传播，得到预测结果。</li><li>将预测结果与真实标签送入损失函数，计算loss。</li><li>调用 <code>loss.backward()</code> 进行反向传播，计算梯度。</li><li>调用 <code>optimizer.step()</code> 更新模型权重。</li><li>清零梯度 (<code>optimizer.zero_grad()</code>)，准备下一次迭代。</li></ul></li></ol><h4 id="_5-pytorch生态系统" tabindex="-1"><a class="header-anchor" href="#_5-pytorch生态系统"><span><strong>5. PyTorch生态系统</strong></span></a></h4><p>PyTorch的强大不仅仅在于其核心库，更在于其庞大且活跃的生态。<code>Hugging Face Transformers</code> 这个“AIGC的基石”库，就是深度构建在PyTorch（和TensorFlow）之上的。它利用PyTorch的底层能力，提供了更高层次、更易于使用的模型接口，让开发者可以不用从零搭建Transformer，而是直接加载和使用预训练好的模型。</p><p><strong>总结</strong>：PyTorch就是那个底层但无比强大的“Spring框架”。它赋予了开发者完全的控制权，虽然写起来可能比更高层封装的库（<a href="http://xn--Kerasfast-k99p786e.ai" target="_blank" rel="noopener noreferrer">如Keras或fast.ai</a>）要“繁琐”一些，但正是这种透明度和灵活性，使其成为驱动当今几乎所有前沿AI研究和应用（包括大语言模型）的首选引擎。</p></div><!----><!----><!----></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">最近更新</span><time class="vp-meta-info" datetime="2025-07-30T02:46:26.000Z" data-allow-mismatch>2025/7/30 10:46</time></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 34129858+codingXuan@users.noreply.github.com">codingXuan</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><!----><a class="route-link auto-link next" href="/knowledge-base/tech/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/TensorFlow_Keras.html" aria-label="TensorFlow Keras"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">TensorFlow Keras<i class="vp-icon fas fa-file-lines" sizing="height"></i></div></a></nav><!----><!----><!--]--></main><!--]--><!----></div><!--]--><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/knowledge-base/assets/app-Cr2W10WY.js" defer></script>
  </body>
</html>

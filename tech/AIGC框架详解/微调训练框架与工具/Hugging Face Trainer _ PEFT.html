<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.94" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <title>Hugging Face Trainer _ PEFT | 我的知识库</title><meta name="description" content="一个记录学习与思考的地方">
    <link rel="preload" href="/knowledge-base/assets/style-Dmo5Xz_6.css" as="style"><link rel="stylesheet" href="/knowledge-base/assets/style-Dmo5Xz_6.css">
    <link rel="modulepreload" href="/knowledge-base/assets/app-BmWXErMj.js"><link rel="modulepreload" href="/knowledge-base/assets/Hugging Face Trainer _ PEFT.html-CO_co3Of.js"><link rel="modulepreload" href="/knowledge-base/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/knowledge-base/assets/index.html-BafRntHS.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-Bf46Ia-A.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-Dgu3bWjA.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/knowledge-management.html-GnxoW7lJ.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/retrospective.html-BCjVhJQf.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/change-management.html-DvGxzfVk.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/meeting-management.html-DXBIkn-t.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/scrum.html-Z0RDF4ti.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/tracking.html-jQt-8evn.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/estimation.html-C8G1UPSI.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/risk-management.html-Bo8XFm6g.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/stakeholder-analysis.html-GbfdRtbJ.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/wbs.html-B0KbonwJ.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/dora-metrics.html-CsSHSZh9.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/leadership.html-B_wNsgiX.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/okr.html-CCWSOzwv.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/pm-pdm-collaboration.html-Cyjwy2h0.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/AIGC应用层建设思路.html-DAhAVoF2.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/RAG建设.html-bUPB4n6D.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-DMsFCWac.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/prompt工程.html-BRfFj3k3.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/业务流程控制-agent.html-DhLPcnTL.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/多agent组合.html-DM9ebvym.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/安全、隐私与伦理.html-CsvLfU7S.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/微调策略.html-DJi49ZMl.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/模型评估与迭代.html-LyQU2k3B.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/训练策略.html-nNlOlknz.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/部署与运维.html-CBsAlPE7.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/长文本与算力.html-BWa9BZRz.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-Cy6mVC5C.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-BNpQ2nnc.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/TGI.html-DbyTZQ0u.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/vLLM.html-k4XEhWRk.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-a4YZuVZA.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/pt_ft.html-CKhZtdez.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/rag.html-jibbUpyx.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/rlhf_dpo.html-Be63FRK0.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/AutoGen.html-DdTCbQ6q.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/CrewAI.html-Cwg2Kh5V.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-C8wvEm0d.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-ClO3daZg.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-CLolyKtd.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/DeepSpeed.html-BD-XQgrd.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/Llama-Alpaca-Factory.html-B1roCklU.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-CIz6PDYh.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/ChromaDB _ Weaviate.html-Dg-bzAW_.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-C_1Xd14p.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/faiss库.html-_7blanpD.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/milvus.html-BT5gKdNn.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/BGE模型.html-CQLtquih.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/M3E模型.html-C0XNERob.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-D3lTtQLT.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/text-embedding-ada-002模型.html-kf776y9v.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/LangChain.html-CVLdzQgZ.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/LlamaIndex.html-Db9y-oGd.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-Copk7wim.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-DAkNJFGL.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/文本分割器-Text Splitters.html-Dqf_tzQy.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/文档加载器-Document Loaders.html-DrjT3dHC.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/Hugging Face Transformers.html-4gFV3E7D.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-Jw2gS3gr.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/Pytorch.html-RL5CZItk.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-DlVGSaO5.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/TensorFlow_Keras.html-Dzfvcggc.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/404.html-C77ELS3c.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-Mb4MNBVq.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-DhhHD2eZ.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-CeWvs9P4.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-eb9ZBTRA.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-DMErE1EG.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-RkY44lf3.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-DuFIZnYW.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-fJg7sB4i.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-bo2RfRm5.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/photoswipe.esm-CKV1Bsxh.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/knowledge-base/" aria-label="带我回家"><!----><!----><span class="vp-site-name">我的知识库</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/knowledge-base/" aria-label="首页"><!--[--><i class="vp-icon fas fa-home" sizing="height"></i><!--]-->首页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/knowledge-base/management/" aria-label="管理随笔"><!--[--><i class="vp-icon fas fa-people-roof" sizing="height"></i><!--]-->管理随笔<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/knowledge-base/tech/" aria-label="技术随笔"><!--[--><i class="vp-icon fas fa-code" sizing="height"></i><!--]-->技术随笔<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!----><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">AIGC应用层建设思路</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">AIGC框架详解</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">基础框架</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">微调训练框架与工具</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/knowledge-base/tech/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E4%B8%8E%E5%B7%A5%E5%85%B7/DeepSpeed.html" aria-label="DeepSpeed"><!--[--><i class="vp-icon fas fa-file-lines fa-fw" sizing="both"></i><!--]-->DeepSpeed<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/knowledge-base/tech/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E4%B8%8E%E5%B7%A5%E5%85%B7/Hugging%20Face%20Trainer%20_%20PEFT.html" aria-label="Hugging Face Trainer 与 PEFT"><!--[--><i class="vp-icon fas fa-file-lines fa-fw" sizing="both"></i><!--]-->Hugging Face Trainer 与 PEFT<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/knowledge-base/tech/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E4%B8%8E%E5%B7%A5%E5%85%B7/Llama-Alpaca-Factory.html" aria-label="Llama-Alpaca-Factory"><!--[--><i class="vp-icon fas fa-file-lines fa-fw" sizing="both"></i><!--]-->Llama-Alpaca-Factory<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">RAG核心组件</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">Agent框架</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">推理服务与部署</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><i class="vp-icon fas fa-folder fa-fw" sizing="both"></i><span class="vp-sidebar-title">数据结构汇总</span><span class="vp-arrow end"></span></button><!----></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Hugging Face Trainer _ PEFT</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">codingXuan</span></span><span property="author" content="codingXuan"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025/3/20</span><meta property="datePublished" content="2025-03-20T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 4 分钟</span><meta property="timeRequired" content="PT4M"></span><!----><!----></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><h4 id="_1-hugging-face-trainer-训练流程的-高级自动化" tabindex="-1"><a class="header-anchor" href="#_1-hugging-face-trainer-训练流程的-高级自动化"><span><strong>1. Hugging Face <strong><code>**Trainer**</code></strong>：训练流程的“高级自动化”</strong></span></a></h4><p><code>Trainer</code> 是 Hugging Face <code>transformers</code> 库中提供的一个高度封装、功能强大的训练工具类。它的核心目标，就是<strong>将开发者从手动编写PyTorch训练循环的繁琐工作中解放出来</strong>。</p><p><strong>A. 核心组件</strong></p><p>使用<code>Trainer</code>主要涉及两个核心类：</p><ol><li><code>**TrainingArguments**</code>: 这是一个数据类，用于<strong>集中管理所有训练相关的超参数和配置</strong>。我们之前在“微调策略”文档中讨论过的所有参数（学习率、批次大小、训练轮次/步数、保存策略、评估策略、梯度累积、DeepSpeed配置等），都在这里进行设置。</li><li><code>**Trainer**</code>: 这是主类。在实例化时，需要将以下核心对象传递给它： <ul><li><code>model</code>：您想要训练的模型。</li><li><code>args</code>：一个<code>TrainingArguments</code>的实例。</li><li><code>train_dataset</code>：训练数据集。</li><li><code>eval_dataset</code>：评估数据集。</li><li><code>tokenizer</code>：模型对应的分词器。</li></ul></li></ol><p><strong>B. 它解决了什么痛点？</strong></p><p>如果手动编写PyTorch训练循环，需要自己处理：</p><ul><li>数据的批次化（Batching）和设备转移（CPU/GPU）。</li><li>模型的<code>train()</code>和<code>eval()</code>模式切换。</li><li>梯度清零、反向传播、参数更新的完整流程。</li><li>在多个GPU上进行分布式训练的复杂设置。</li><li>混合精度训练（FP16/BF16）的配置。</li><li>日志记录、评估循环、模型检查点（Checkpoint）的保存。</li></ul><p>而<code>Trainer</code>将这一切全部封装好了。只需配置好<code>TrainingArguments</code>，然后调用 <code>**trainer.train()**</code>，所有上述工作都会被自动、健壮地执行。</p><h4 id="_2-peft-库-参数高效微调的-瑞士军刀" tabindex="-1"><a class="header-anchor" href="#_2-peft-库-参数高效微调的-瑞士军刀"><span>**2. **<code>**PEFT**</code><strong>库：参数高效微调的“瑞士军刀”</strong></span></a></h4><p>PEFT (Parameter-Efficient Fine-Tuning) 是Hugging Face推出的一个开源库，旨在让大模型的微调变得更亲民、更高效。它集成了多种高效微调技术，其中最耀眼的明星就是<strong>LoRA</strong>和<strong>QLoRA</strong>。</p><ul><li><strong>核心思想</strong>：在微调时，冻结（freeze）高达99.9%的原始模型参数，仅训练一小部分新增的、可插拔的“适配器（Adapter）”参数。</li><li><code>**peft**</code><strong>库的关键操作</strong>： <ol><li><strong>定义配置 (</strong><code>**LoraConfig**</code><strong>)</strong>：创建一个配置对象，在其中定义LoRA的参数，如秩（<code>r</code>）、alpha值（<code>lora_alpha</code>）、要应用LoRA的层（<code>target_modules</code>）等。</li><li><strong>包装模型 (</strong><code>**get_peft_model**</code><strong>)</strong>：调用<code>get_peft_model</code>函数，将原始<code>transformers</code>模型和一个<code>LoraConfig</code>传入，它会返回一个被“魔法”改造过的、可训练的PEFT模型。这个新模型在训练时，只有LoRA适配器的权重会被更新。</li></ol></li></ul><h4 id="_3-黄金搭档-trainer-peft-的协同工作流" tabindex="-1"><a class="header-anchor" href="#_3-黄金搭档-trainer-peft-的协同工作流"><span><strong>3. 黄金搭档：</strong><code>**Trainer**</code>** + <strong><code>**PEFT**</code></strong> 的协同工作流**</span></a></h4><p>这两者可以无缝集成，形成一套极其强大且易于使用的微调工作流。</p><p><strong>一个典型的QLoRA微调流程如下：</strong></p><p><strong>加载量化模型</strong>：使用<code>transformers</code>库，以4-bit量化的形式加载基础大模型（例如Qwen2）。这一步极大地降低了模型的基础显存占用。</p><ol><li>Python</li></ol><div class="language-plain line-numbers-mode" data-highlighter="shiki" data-ext="plain" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-plain"><span class="line"><span>from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig</span></span>
<span class="line"><span></span></span>
<span class="line"><span>model_name = &quot;Qwen/Qwen2-7B-Instruct&quot;</span></span>
<span class="line"><span>quantization_config = BitsAndBytesConfig(load_in_4bit=True) # QLoRA的关键</span></span>
<span class="line"><span></span></span>
<span class="line"><span>model = AutoModelForCausalLM.from_pretrained(</span></span>
<span class="line"><span>    model_name,</span></span>
<span class="line"><span>    quantization_config=quantization_config,</span></span>
<span class="line"><span>    device_map=&quot;auto&quot; # 自动将模型分配到可用设备</span></span>
<span class="line"><span>)</span></span>
<span class="line"><span>tokenizer = AutoTokenizer.from_pretrained(model_name)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>配置PEFT (LoRA)</strong>：使用<code>peft</code>库定义LoRA适配器的配置。</p><ol start="2"><li>Python</li></ol><div class="language-plain line-numbers-mode" data-highlighter="shiki" data-ext="plain" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-plain"><span class="line"><span>from peft import LoraConfig, get_peft_model</span></span>
<span class="line"><span></span></span>
<span class="line"><span>lora_config = LoraConfig(</span></span>
<span class="line"><span>    r=8, # LoRA的秩，是效果和参数量的权衡</span></span>
<span class="line"><span>    lora_alpha=32,</span></span>
<span class="line"><span>    target_modules=[&quot;q_proj&quot;, &quot;v_proj&quot;], # 指定在哪些层上应用LoRA</span></span>
<span class="line"><span>    lora_dropout=0.1,</span></span>
<span class="line"><span>    task_type=&quot;CAUSAL_LM&quot;</span></span>
<span class="line"><span>)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 将LoRA适配器应用到量化后的模型上</span></span>
<span class="line"><span>peft_model = get_peft_model(model, lora_config)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>使用</strong><code>**Trainer**</code><strong>进行训练</strong>：</p><pre><code>- 定义`TrainingArguments`，配置学习率、步数等。
- 将我们刚刚创建的 `peft_model` 传递给`Trainer`。
</code></pre><ol start="3"><li>Python</li></ol><div class="language-plain line-numbers-mode" data-highlighter="shiki" data-ext="plain" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-plain"><span class="line"><span>from transformers import TrainingArguments, Trainer</span></span>
<span class="line"><span></span></span>
<span class="line"><span>training_args = TrainingArguments(</span></span>
<span class="line"><span>    output_dir=&quot;./qwen2-7b-sft&quot;,</span></span>
<span class="line"><span>    per_device_train_batch_size=4,</span></span>
<span class="line"><span>    gradient_accumulation_steps=4,</span></span>
<span class="line"><span>    learning_rate=2e-4,</span></span>
<span class="line"><span>    max_steps=1000,</span></span>
<span class="line"><span>    # ... 其他所有训练参数</span></span>
<span class="line"><span>)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>trainer = Trainer(</span></span>
<span class="line"><span>    model=peft_model, # 注意：这里传入的是PEFT模型！</span></span>
<span class="line"><span>    args=training_args,</span></span>
<span class="line"><span>    train_dataset=your_dataset,</span></span>
<span class="line"><span>    # ...</span></span>
<span class="line"><span>)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 一键启动所有训练流程</span></span>
<span class="line"><span>trainer.train()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>协同的“魔法”</strong>：<code>Trainer</code>能够智能地识别出传入的是一个PEFT模型。因此，在训练结束后，当保存模型时，它<strong>只会保存轻量级的LoRA适配器权重</strong>（通常只有几十MB），而不是整个几十GB的大模型，这极大地便利了模型的存储和分发。</p><h4 id="_4-总结-现代llm微调的-事实标准" tabindex="-1"><a class="header-anchor" href="#_4-总结-现代llm微调的-事实标准"><span><strong>4. 总结：现代LLM微调的“事实标准”</strong></span></a></h4><ul><li><code>**Trainer**</code> 解决了LLM微调中 <strong>“流程”</strong> 的问题，它提供了一个健壮、功能丰富且易于使用的自动化训练器。</li><li><code>**PEFT**</code> 解决了LLM微调中 <strong>“资源”</strong> 的问题，它让开发者可以在消费级的硬件上，高效地对超大规模的模型进行个性化定制。</li></ul><p><code>**Trainer**</code>** + <strong><code>**PEFT**</code></strong> 的组合**，已经成为当今开源社区进行大语言模型微调的“事实标准”，它完美地平衡了<strong>易用性、功能强大性与资源高效性</strong>，是每一位AIGC应用开发者都应该熟练掌握的核心工具。</p></div><!----><!----><!----></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">最近更新</span><time class="vp-meta-info" datetime="2025-07-30T02:46:26.000Z" data-allow-mismatch>2025/7/30 10:46</time></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 34129858+codingXuan@users.noreply.github.com">codingXuan</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/knowledge-base/tech/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E4%B8%8E%E5%B7%A5%E5%85%B7/DeepSpeed.html" aria-label="DeepSpeed"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><i class="vp-icon fas fa-file-lines" sizing="height"></i>DeepSpeed</div></a><a class="route-link auto-link next" href="/knowledge-base/tech/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E4%B8%8E%E5%B7%A5%E5%85%B7/Llama-Alpaca-Factory.html" aria-label="Llama-Alpaca-Factory"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">Llama-Alpaca-Factory<i class="vp-icon fas fa-file-lines" sizing="height"></i></div></a></nav><!----><!----><!--]--></main><!--]--><!----></div><!--]--><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/knowledge-base/assets/app-BmWXErMj.js" defer></script>
  </body>
</html>

<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.94" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <title>TGI | 我的知识库</title><meta name="description" content="一个记录学习与思考的地方">
    <link rel="preload" href="/knowledge-base/assets/style-Dmo5Xz_6.css" as="style"><link rel="stylesheet" href="/knowledge-base/assets/style-Dmo5Xz_6.css">
    <link rel="modulepreload" href="/knowledge-base/assets/app-Dxd7UrXP.js"><link rel="modulepreload" href="/knowledge-base/assets/TGI.html-C_eBGuwZ.js"><link rel="modulepreload" href="/knowledge-base/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/knowledge-base/assets/index.html-CP8x-3zB.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/AIGC应用层建设思路.html-CrXhYGrt.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/RAG建设.html-3M40DIqr.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-reutSDve.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/prompt工程.html-BmDZ3WoL.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/业务流程控制-agent.html-ClcirRgu.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/多agent组合.html-fyeeZ_qJ.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/安全、隐私与伦理.html-CcTXXUEh.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/微调策略.html-9sEMmTGB.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/模型评估与迭代.html-Oehsakmg.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/训练策略.html-Cp_zXQAe.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/部署与运维.html-DOwelw60.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/长文本与算力.html-Cqz8-_d0.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-DfzVnE1k.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-R_VULKfk.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/vLLM.html-Cl1WCMbl.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-CPhQGgeR.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/pt_ft.html-C0W2aoFC.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/rag.html-D5WoqJeB.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/rlhf_dpo.html-DLZCTRpm.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/AutoGen.html-BH7Wf0Oj.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/CrewAI.html-CY5CWdV5.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-B0qtDkZy.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-CyviWr2x.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/DeepSpeed.html-CEMYI2mB.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/Hugging Face Trainer _ PEFT.html-BSVyMWCA.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/Llama-Alpaca-Factory.html-CmfU0WYy.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-n57pKtDR.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-BQuwYOmw.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/BGE模型.html-DK4Wuf7k.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/M3E模型.html-DBc3SXwC.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-CXXmSgit.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/text-embedding-ada-002模型.html-95Akx3wP.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/ChromaDB _ Weaviate.html-C3VggJsG.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-Ct8aO-Cz.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/faiss库.html-BQPzIxtw.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/milvus.html-CkQ4WD69.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-kgLrsNxN.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/文本分割器-Text Splitters.html-B1G-621Y.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/文档加载器-Document Loaders.html-kg0sQ2SB.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/Hugging Face Transformers.html-CCe6qJdY.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-RDp7Rrdb.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/Pytorch.html-C2EHjq-h.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-CAGr60Cl.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/TensorFlow_Keras.html-B8p4cYiU.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/LangChain.html-CHnkCaZf.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/LlamaIndex.html-nP9zGhTF.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-Bu0h-ksx.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/404.html-CwOTbrAy.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-DivRaM6P.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-B1Qy_VRa.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-DS7i5Dn4.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-BRXFyZpv.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/index.html-B2qN71el.js" as="script"><link rel="prefetch" href="/knowledge-base/assets/photoswipe.esm-CKV1Bsxh.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/knowledge-base/" aria-label="带我回家"><!----><!----><span class="vp-site-name">我的知识库</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/knowledge-base/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/knowledge-base/AIGC%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/" aria-label="AIGC框架"><!---->AIGC框架<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/knowledge-base/AIGC%E5%BA%94%E7%94%A8%E5%B1%82%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%B7%AF/" aria-label="AIGC应用"><!---->AIGC应用<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/knowledge-base/%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1%E4%B8%8E%E9%83%A8%E7%BD%B2/" aria-label="推理部署"><!---->推理部署<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/knowledge-base/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%B1%87%E6%80%BB/" aria-label="数据结构"><!---->数据结构<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!----><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">AIGC应用层建设思路</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">AIGC框架详解</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">推理服务与部署</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/knowledge-base/%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1%E4%B8%8E%E9%83%A8%E7%BD%B2/vLLM.html" aria-label="vLLM"><!--[--><i class="vp-icon fas fa-file-lines fa-fw" sizing="both"></i><!--]-->vLLM<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/knowledge-base/%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1%E4%B8%8E%E9%83%A8%E7%BD%B2/TGI.html" aria-label="TGI"><!--[--><i class="vp-icon fas fa-file-lines fa-fw" sizing="both"></i><!--]-->TGI<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">数据结构汇总</span><span class="vp-arrow end"></span></button><!----></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->TGI</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">codingXuan</span></span><span property="author" content="codingXuan"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025/7/29</span><meta property="datePublished" content="2025-07-29T03:02:15.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 4 分钟</span><meta property="timeRequired" content="PT4M"></span><!----><!----></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><h4 id="_1-核心定位-hugging-face官方出品的-生产级-推理解决方案" tabindex="-1"><a class="header-anchor" href="#_1-核心定位-hugging-face官方出品的-生产级-推理解决方案"><span><strong>1. 核心定位：Hugging Face官方出品的“生产级”推理解决方案</strong></span></a></h4><p>TGI (Text Generation Inference) 是一个专门为大规模语言模型设计的、功能全面且经过生产环境严苛考验的推理服务器。</p><p>作为Hugging Face的“亲儿子”，它的首要目标就是为<strong>Hugging Face Hub</strong>上数以万计的Transformer模型，提供一个官方的、开箱即用的、高性能的部署方案。它被广泛地应用于Hugging Face自己的产品中，如HuggingChat和Inference API服务，其稳定性和可靠性得到了充分验证。</p><h4 id="_2-tgi的核心特性-功能全面-为生产而生" tabindex="-1"><a class="header-anchor" href="#_2-tgi的核心特性-功能全面-为生产而生"><span><strong>2. TGI的核心特性：功能全面，为生产而生</strong></span></a></h4><p>TGI同样集成了当前最前沿的推理优化技术，以提供强大的性能。</p><ul><li><strong>持续批处理 (Continuous Batching)</strong>：和vLLM一样，TGI也采用了持续批处理技术来最大化GPU的利用率，显著提升吞吐量。</li><li><strong>张量并行 (Tensor Parallelism)</strong>：内置了对张量并行的支持，可以轻松地将一个因太大而无法装入单张GPU的模型，拆分到多张GPU上进行协同推理。</li><li><strong>模型量化 (Quantization)</strong>：支持在服务启动时，动态地将模型权重进行量化（例如，使用bitsandbytes的NF4或Gradio的AWQ/GPTQ），从而在几乎不损失性能的情况下，大幅降低显存占用。</li><li><strong>优化的计算核与FlashAttention</strong>：TGI为其支持的模型，深度集成了包括<strong>FlashAttention-2</strong>在内的一系列高度优化的CUDA计算核，从底层保证了计算效率。</li><li><strong>水印功能 (Watermarking)</strong>：内置了为生成文本添加水印的功能，有助于追踪AI生成内容的来源。</li><li><strong>流式输出与安全性 (Streaming &amp; Safety)</strong>：原生支持Token流式输出，并提供了停止序列（stop sequences）、最大Token数限制等安全功能，防止滥用。</li></ul><h4 id="_3-tgi的使用方式-以docker为核心" tabindex="-1"><a class="header-anchor" href="#_3-tgi的使用方式-以docker为核心"><span><strong>3. TGI的使用方式：以Docker为核心</strong></span></a></h4><p>TGI的设计理念是**“容器优先”**。官方推荐的使用方式是通过Docker容器来运行，这极大地简化了部署和环境配置的复杂性。</p><ol><li><strong>准备工作</strong>：安装NVIDIA驱动和NVIDIA Container Toolkit。</li></ol><p><strong>使用Docker命令启动服务</strong>： 只需要一条<code>docker run</code>命令即可启动一个完整的TGI服务。</p><ol start="2"><li>Bash</li></ol><div class="language-plain line-numbers-mode" data-highlighter="shiki" data-ext="plain" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-plain"><span class="line"><span># 定义一个变量来存储您的Hugging Face Hub缓存目录</span></span>
<span class="line"><span>export MODEL_CACHE=$HOME/.cache/huggingface/hub</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 定义模型ID</span></span>
<span class="line"><span>export MODEL_ID=Qwen/Qwen3-32B-Instruct</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 运行Docker容器</span></span>
<span class="line"><span>docker run --gpus all --shm-size 1g -p 8080:80 \</span></span>
<span class="line"><span>    -v $MODEL_CACHE:/data \</span></span>
<span class="line"><span>    ghcr.io/huggingface/text-generation-inference:latest \</span></span>
<span class="line"><span>    --model-id $MODEL_ID</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><pre><code>- `**--gpus all**`: 将所有可用的GPU分配给容器。
- `**-p 8080:80**`: 将主机的8080端口映射到容器的80端口。
- `**-v $MODEL_CACHE:/data**`: 将您本地的Hugging Face缓存目录挂载到容器中，这样TGI就可以直接使用您已经下载过的模型，避免重复下载。
- `**--model-id $MODEL_ID**`: 指定需要加载和服务的模型。
</code></pre><p><strong>调用服务</strong>： 服务启动后，您可以通过标准的HTTP请求来调用它。</p><ol start="3"><li>Python</li></ol><div class="language-plain line-numbers-mode" data-highlighter="shiki" data-ext="plain" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-plain"><span class="line"><span>import requests</span></span>
<span class="line"><span>import json</span></span>
<span class="line"><span></span></span>
<span class="line"><span>headers = {&quot;Content-Type&quot;: &quot;application/json&quot;}</span></span>
<span class="line"><span>api_url = &quot;http://localhost:8080/generate&quot;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>payload = {</span></span>
<span class="line"><span>    &quot;inputs&quot;: &quot;你好，请介绍一下Text Generation Inference (TGI)。&quot;,</span></span>
<span class="line"><span>    &quot;parameters&quot;: {</span></span>
<span class="line"><span>        &quot;max_new_tokens&quot;: 512,</span></span>
<span class="line"><span>        &quot;temperature&quot;: 0.7</span></span>
<span class="line"><span>    }</span></span>
<span class="line"><span>}</span></span>
<span class="line"><span></span></span>
<span class="line"><span>response = requests.post(api_url, headers=headers, json=payload)</span></span>
<span class="line"><span>print(response.json())</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_4-tgi-vs-vllm-如何进行技术选型" tabindex="-1"><a class="header-anchor" href="#_4-tgi-vs-vllm-如何进行技术选型"><span><strong>4. TGI vs. vLLM：如何进行技术选型</strong></span></a></h4><table><thead><tr><th>特性</th><th><strong>TGI (Hugging Face)</strong></th><th><strong>vLLM (UC Berkeley / vLLM Team)</strong></th></tr></thead><tbody><tr><td><strong>核心优势技术</strong></td><td>持续批处理, FlashAttention, 全面的生产级特性</td><td><strong>PagedAttention</strong>, 持续批处理</td></tr><tr><td><strong>性能表现</strong></td><td>性能非常高，稳定可靠</td><td><strong>通常在吞吐量上略有优势</strong>，尤其是在长尾请求分布场景</td></tr><tr><td><strong>功能丰富度</strong></td><td><strong>更高</strong>，内置水印、更完善的安全配置、与HF生态深度集成</td><td>专注于核心的推理性能，功能相对精简</td></tr><tr><td><strong>易用性</strong></td><td><strong>非常易用</strong>，以Docker为核心，一条命令即可启动</td><td>同样易用，提供了OpenAI兼容服务器和Python库两种模式</td></tr><tr><td><strong>模型支持</strong></td><td>由Hugging Face官方维护，支持广泛且经过严格测试</td><td>社区驱动，支持同样广泛，但有时对新模型的支持速度更快</td></tr></tbody></table><p><strong>选型建议</strong>：</p><ul><li><strong>追求极致吞TPut</strong>：如果业务场景对<strong>吞吐量（Throughput）的要求是第一位的，那么vLLM</strong>通常是更优的选择，其PagedAttention技术在理论和实践中都展现了卓越的性能。</li><li><strong>追求功能全面与生态整合</strong>：如果深度使用Hugging Face生态，需要一个<strong>功能全面、稳定可靠、官方支持</strong>的“全家桶”式解决方案，那么<strong>TGI</strong>是更稳妥、更省心的选择。</li><li>在实际生产中，团队通常会对两者进行<strong>基准测试（Benchmark）</strong>，根据自己核心使用的模型和业务负载特点，来决定最终采用哪个框架。</li></ul><p><strong>总结</strong>：TGI是Hugging Face为整个AI社区提供的、官方的、生产级的推理服务解决方案。它以其<strong>全面的功能、稳健的性能和与HF生态的无缝集成</strong>而著称，是任何希望将LLM应用部署到生产环境的团队都必须考虑的重要选项。</p></div><!----><!----><!----></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">最近更新</span><time class="vp-meta-info" datetime="2025-07-29T03:02:15.000Z" data-allow-mismatch>2025/7/29 11:02</time></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 34129858+codingXuan@users.noreply.github.com">codingXuan</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/knowledge-base/%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1%E4%B8%8E%E9%83%A8%E7%BD%B2/vLLM.html" aria-label="vLLM"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><i class="vp-icon fas fa-file-lines" sizing="height"></i>vLLM</div></a><!----></nav><!----><!----><!--]--></main><!--]--><!----></div><!--]--><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/knowledge-base/assets/app-Dxd7UrXP.js" defer></script>
  </body>
</html>
